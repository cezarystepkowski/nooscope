<!DOCTYPE html>
<!--[if IE 8]>
<html lang="pl" class="ie8 no-js"> <![endif]-->
<!--[if IE 9]>
<html lang="pl" class="ie9 no-js"> <![endif]-->
<!--[if !IE]><!-->
<html class="js flexbox canvas canvastext webgl no-touch geolocation postmessage no-websqldatabase indexeddb hashchange history draganddrop websockets rgba hsla multiplebgs backgroundsize borderimage borderradius boxshadow textshadow opacity cssanimations csscolumns cssgradients no-cssreflections csstransforms csstransforms3d csstransitions fontface generatedcontent video audio localstorage sessionstorage webworkers applicationcache svg inlinesvg smil svgclippaths" lang="pl">
    <!--<![endif]-->
    <head>
        <meta http-equiv="content-type" content="text/html; charset=UTF-8">

        <meta charset="UTF-8">

        <title>Nooskop ujawniony – manifest</title>

        <meta name="viewport" content="width=device-width, initial-scale=1.0, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="keywords" content="AI,machine learning,praca,automatyzacja,wyzysk,badania,Amazon,teoria mediów,wizualizacja">
        <meta name="description" content="Sztuczna inteligencja jako narzędzie ekstraktywizmu wiedzy. Autorzy Matteo Pasquinelli i Vladan Joler">

        <link href="vendor/font-awesome/css/font-awesome.css" rel="stylesheet" type="text/css">
        <link href="vendor/bootstrap/css/bootstrap.css" rel="stylesheet">
        <link href="css/main.css" rel="stylesheet">
        <style type="text/css">
            .nooscope-reference-num {
                margin-left: -.2em;
                margin-right: .2em;
            }
            .nooscope-translator-reference-list {
                border-top: 1px solid #000;
                margin-top: 2em;
            }
            .nooscope-translator-reference-list-item {
                padding: 0.5rem;
            }
        </style>

        <!-- Favicon ico -->
        <link rel="shortcut icon" href="favicon.ico">


        <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
        <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
        <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
        <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
        <![endif]-->

    </head>

    <body id="ai-page-top">

        <!-- Nooscope map -->
        <div class="nooscope-image-map-wrap text-center">

            <div class="ai-image-map bottom_padding"></div>
            <!-- @todo linki do diagramu i eseju -->
            <p class="small marging_top">Pobierz
                diagram PDF (wkrótce dostępny) i esej PDF (wkrótce dostępny)
<!--                <a href="#" target="_blank">diagram PDF</a> (wkrótce dostępny) i-->
<!--                <a href="#" target="_blank">esej PDF</a> (wkrótce dostępny)-->
            </p>
        </div>

        <!-- HEADER -->
        <header class="d-flex text-center">
            <div class="container align-self-center">
                <h2></h2>
                <div class="row justify-content-center mb-4 mb-sm-4 mb-md-4 mb-lg-4 mb-xl-4">
                    <div class="col-12 col-sm-12 col-md-9 col-lg-9 col-xl-8">
                        <h1>Nooskop ujawniony – manifest</h1>
                        <h5 class="bottom_padding">Sztuczna inteligencja jako narzędzie ekstraktywizmu wiedzy</h5>
                        <br>
                        <p>
                            Vladan Joler i Matteo Pasquinelli
                            <br>(2020)
                        </p>
                    </div>
                </div>
                <div class="ai-img-wrap text-center mt-5 mt-sm-5 mt-md-5 mt-lg-5 mt-xl-5">
                    <img class="img-fluid" src="img/Nooscope2_AC_00.svg" alt="Soczewki">
                </div>
            </div>
        </header>

        <!-- MAIN CONTENT -->
        <main class="mt-5 mt-sm-5 mt-md-5 mt-lg-5 mt-xl-5">
            <div class="container">
                <div class="row justify-content-center">
                    <div class="col-12 col-sm-12 col-md-9 col-lg-9 col-xl-8">
                        <article class="ai-main-content">
                            <section>
                                <h2>1. Nieco oświecenia w kwestii mechanizacji rozumu</h2>
                                <p>Nooskop to kartografia granic sztucznej inteligencji pomyślana jako prowokacja zarówno wobec informatyki, jak i humanistyki. Każda mapa pokazuje tylko część perspektywy, jest sposobem wywołania debaty. Również i ta mapa jest manifestem – manifestem dysydentów SI. Jej głównym celem jest rzucenie wyzwania mistyfikacjom sztucznej inteligencji. Po pierwsze jako technicznej definicji <strong>inteligencji</strong>, a po drugie jako formie politycznej, która miałaby być <strong>autonomiczna</strong> względem społeczeństwa i tego, co ludzkie<a href="#nooscope-ref-01-bottom" id="nooscope-ref-01-top" class="nooscope-reference-num ai-scroll-to" data-toggle="tooltip" data-html="true" data-original-title="Na temat autonomii technologii zob. Langdon Winner, &lt;cite&gt;Autonomous Technology: Technics-Out-of-Control as a Theme in Political Thought&lt;/cite&gt;. Cambridge, MA: MIT Press, 2001."><sup>1</sup></a>. W wyrażeniu „sztuczna inteligencja” przymiotnik „sztuczna” jest nośnikiem mitu o autonomii technologii – wskazuje na karykaturalne „pozaludzkie umysły”, które samodzielnie reprodukują się <i>in silico</i>, lecz w rzeczywistości przysłania dwa procesy prawdziwej alienacji: rosnącą geopolityczną autonomię firm technologicznych i zanikanie autonomii pracowników na całym świecie. Nowoczesny projekt mechanizacji ludzkiego umysłu w XXI wieku najwyraźniej zmutował w korporacyjny reżim ekstraktywizmu wiedzy i poznawczego kolonializmu<a href="#nooscope-ref-02-bottom" id="nooscope-ref-02-top" class="nooscope-reference-num ai-scroll-to" data-toggle="tooltip" data-html="true" data-original-title="O rozszerzeniu władzy kolonialnej na operacje logistyczne, algorytmy i finanse zob. Sandro Mezzadra and Brett Neilson, &lt;cite&gt;The Politics of Operations: Excavating Contemporary Capitalism&lt;/cite&gt;. Durham: Duke University Press, 2019. Na temat epistemicznego kolonializmu AI - zob. Matteo Pasquinelli, „Three Thousand Years of Algorithmic Rituals.” &lt;cite&gt;e-flux&lt;/cite&gt; 101, 2019."><sup>2</sup></a>. Nie ma w tym nic dziwnego, skoro algorytmy uczenia maszynowego są najmocniejszymi algorytmami do kompresowania informacji.</p>
                                <p>Celem mapy nooskopu jest sekularyzacja SI – zmiana jej statusu ideologicznego z „inteligentnej maszyny” na narzędzie wiedzy. Zamiast odwoływać się do legend o pozaludzkim poznaniu rozsądniej byłoby uznać uczenie maszynowe za <strong>przyrząd do powiększania wiedzy</strong>, pomagający dostrzegać cechy, wzorce i korelacje w przepastnych przestrzeniach danych poza zasięgiem człowieka. W historii nauki i technologii już się to zdarzało: przyrządy optyczne pełniły taką rolę w dziejach astronomii i medycyny<a href="#nooscope-ref-03-bottom" id="nooscope-ref-03-top" class="nooscope-reference-num ai-scroll-to" data-toggle="tooltip" data-html="true" data-original-title="W humanistyce cyfrowej funkcjonuje pojęcie &lt;em&gt;czytania zapośredniczonego&lt;/em&gt;, dzięki któremu powoli zaczęto angażować analizę danych i uczenie maszynowe w historię literatury i sztuki. Zob. Franco Moretti, &lt;cite&gt;Distant Reading&lt;/cite&gt;. London: Verso, 2013."><sup>3</sup></a>. Jeśli wpisać je w tradycję nauki, uczenie maszynowe jest jedynie <strong>nooskopem</strong>, przyrządem służącym do spoglądania na przestrzeń wiedzy i nawigowania po niej (od greckiego <i>skopein</i> „badać, patrzeć” i <i>noos</i> „wiedza”).</p>
                                <p>Diagram nooskopu opiera się na pomyśle Gottfrieda Wilhelma Leibniza i sięga do przyrządów optycznych jako analogii dla struktury całego oprzyrządowania uczenia maszynowego. By przedstawić moc swojego <i>calculus ratiocinator</i> i „znaków graficznych lub umownych” (był to pomysł, by zaprojektować numeryczny, uniwersalny język, w którym można by zakodować i rozwiązać wszystkie problemy ludzkiego rozumowania), Leibniz posłużył się analogią do przyrządów powiększania obrazu, takich jak mikroskop i teleskop. Pisał: <q>Śmiem twierdzić, że to<a href="#nooscope-translator-ref-01-bottom" id="nooscope-translator-ref-01-top" class="nooscope-reference-asterisk ai-scroll-to" data-toggle="tooltip" data-html="true" data-original-title="wynalezienie znaków graficznych lub umownych — przyp. tłum.">*</a> właśnie stanowi ostateczny wysiłek ducha ludzkiego, a kiedy projekt zostanie wykonany, osiągnięcie szczęścia będzie zależało już tylko od ludzi, posiądą bowiem narzędzie, które nie mniej posłuży do wywyższenia rozumu, niż teleskop służy do wzmocnienia wzroku<a href="#nooscope-ref-04-bottom" id="nooscope-ref-04-top" class="nooscope-reference-num ai-scroll-to" data-toggle="tooltip" data-html="true" data-original-title="Gottfried W. Leibniz, „Przedmowa do nauki ogólnej”, 1677. W: tenże &lt;cite&gt;Wyznanie wiary filozofa...&lt;/cite&gt;, przeł. S. Cichowicz i in. Warszawa, 1969, 74."><sup>4</sup></a></q>. Nie chodzi nam o to, by po raz kolejny mówić o opozycji między kulturami jakościowymi i ilościowymi, ale lepiej nie podążać za credo Leibniza. Kontrowersji nie da się przeliczyć w sposób jednoznaczny. Uczenie maszynowe nie jest najwyższą formą inteligencji.</p>
                                <p>W przyrządy pomiaru i postrzegania zawsze wbudowane są pewne odchylenia. Tak jak soczewki mikroskopu czy teleskopu nigdy nie mają idealnej gładkości i krzywizny, tak samo <em>logiczne soczewki</em> uczenia maszynowego zawierają usterki i błędy<a href="#nooscope-translator-ref-02-bottom" id="nooscope-translator-ref-02-top" class="nooscope-reference-asterisk ai-scroll-to" data-toggle="tooltip" data-html="true" data-original-title="Angielske słowo &lt;em&gt;bias&lt;/em&gt; tłumaczymy w zależności od kontekstu jako błąd (systematyczny), stronniczość, ludzkie uprzedzenie. W polskiej literaturze dot. uczenia maszynowego pojawia się termin &lt;em&gt;obciążenie modelu&lt;/em&gt;, który nie oddaje wszystkich sensów słowa &lt;em&gt;bias&lt;/em&gt; tak, jak używają go Autorzy — przyp. tłum.">**</a>. Zrozumieć uczenie maszynowe i udokumentować jego wpływ na społeczeństwo to zbadać, w jakim stopniu społeczne dane ulegają dyfrakcji i zniekształceniu przez owe soczewki. Jest to temat ogólnie znany jako dyskusja nad błędem systematycznym w SI, ale polityczne implikacje logicznej formy uczenia maszynowego są głębsze. Uczenie maszynowe nie sprowadza nowych wieków ciemnych, lecz wiek zniekształconej racjonalności, w której episteme przyczynowości zostaje zastąpione przez episteme korelacji. Jeszcze ogólniej rzecz biorąc, SI to nowy reżim prawdy, dowodzenia naukowego, społecznej normy i racjonalności, który często przybiera kształt <em>halucynacji statystycznej</em>. Ten diagram-manifest to nasz sposób, by powiedzieć, że SI, król obliczeń (patriarchalna fantazja zmechanizowanej wiedzy, „naczelnego algorytmu” i <em>automatu alfa</em>), jest nagi. Tutaj ukradkiem zaglądamy do jego czarnej skrzynki.</p>
                                <figure class="ai-img-wrap text-center mt-5 mt-sm-5 mt-md-5 mt-lg-5 mt-xl-5">
                                    <img class="img-fluid" src="img/Nooscope_01.gif" alt="Emanuele Tesauro, Il canocchiale aristotelico [Teleskop Arystotelesa]">
                                    <figcaption class="nooscope-reference-fig-desc small mt-3 mt-sm-3 mt-md-3 mt-lg-3 mt-xl-3">O wynalezieniu metafor jako narzędzia powiększania wiedzy. Emanuele Tesauro, Il canocchiale aristotelico [Teleskop Arystotelesa], fronton edycji z 1670 roku, Turyn.</figcaption>
                                </figure>
                                <ul class="nooscope-translator-reference-list list-unstyled">
                                    <li class="nooscope-translator-reference-list-item">
                                        <div class="nooscope-translator-reference d-flex flex-row">
                                            <label id="nooscope-translator-ref-01-bottom" class="nooscope-translator-reference-asterisk small mr-1 mr-sm-1 mr-md-1 mr-lg-1 mr-xl-1">
                                                <a href="#nooscope-translator-ref-01-top" class="ai-scroll-to">*</a>
                                            </label>
                                            <p class="nooscope-translator-reference-desc small">wynalezienie znaków graficznych lub umownych — przyp. tłum.</p>
                                        </div>
                                    </li>
                                    <li class="nooscope-translator-reference-list-item">
                                        <div class="nooscope-translator-reference d-flex flex-row">
                                            <label id="nooscope-translator-ref-02-bottom" class="nooscope-translator-reference-asterisk small mr-1 mr-sm-1 mr-md-1 mr-lg-1 mr-xl-1">
                                                <a href="#nooscope-translator-ref-02-top" class="ai-scroll-to">**</a>
                                            </label>
                                            <p class="nooscope-translator-reference-desc small">Angielske słowo <em>bias</em> tłumaczymy w zależności od kontekstu jako błąd (systematyczny), stronniczość, ludzkie uprzedzenie. W polskiej literaturze dot. uczenia maszynowego pojawia się termin <em>obciążenie modelu</em>, który nie oddaje wszystkich sensów słowa <em>bias</em> tak, jak używają go Autorzy — przyp. tłum.</p>
                                        </div>
                                    </li>
                                </ul>
                            </section>

                            <section>
                                <h2>2. Linia montażowa uczenia maszynowego: dane, algorytm, model</h2>
                                <p>Historia SI to historia eksperymentów, maszyn, które zawodzą, akademickich sporów i okresów epickiej rywalizacji o finansowanie przez armię, znanych powszechnie jako „zimy SI”<a href="#nooscope-ref-05-bottom" id="nooscope-ref-05-top" class="nooscope-reference-num ai-scroll-to" data-toggle="tooltip" data-html="true" data-original-title="Aby uzyskać więcej informacji na temat zwięzłej historii SI zob. Dominique Cardon, Jean-Philippe Cointet and Antoine Mazières, „Neurons Spike Back: The Invention of Inductive Machines and the Artificial Intelligence Controversy.” &lt;cite&gt;Réseaux&lt;/cite&gt; 211, 2018."><sup>5</sup></a>. Chociaż dziś korporacyjna SI opisuje swą moc językiem czarnej magii i „nadludzkiego poznania”, obecne rozwiązania nadal są w fazie eksperymentalnej<a href="#nooscope-ref-06-bottom" id="nooscope-ref-06-top" class="nooscope-reference-num ai-scroll-to" data-toggle="tooltip" data-html="true" data-original-title="Alexander Campolo i Kate Crawford, „Enchanted Determinism: Power without Control in Artificial Intelligence.” &lt;cite&gt;Engaging Science, Technology, and Society&lt;/cite&gt; 6, 2020."><sup>6</sup></a>. SI jest teraz na tym samym etapie co maszyna parowa przed odkryciem praw termodynamiki, koniecznych do wyjaśnienia i kontroli jej pracy. Podobnie dziś istnieją wydajne sieci neuronowe rozpoznające obraz, ale nie ma <em>teorii uczenia się</em>, która wyjaśniałaby, dlaczego tak dobrze działają i dlaczego tak bardzo zawodzą. Jak w przypadku każdego odkrycia, paradygmat uczenia maszynowego budował się powoli, w tym wypadku przez ostatnie pół wieku. Naczelny algorytm nie pojawił się z dnia na dzień. Trwa raczej stopniowe konstruowanie metod obliczeniowych, którym brak jeszcze wspólnego słownika. Dla przykładu, akademickie podręczniki uczenia maszynowego nie posługują się jednakową terminologią. Jak więc naszkicować niezbędną gramatykę uczenia maszynowego, która byłaby zwięzła i przystępna, bez wdawania się w paranoiczną zabawę w definiowanie ogólnej inteligencji?</p>
                                <p>Jako narzędzie wiedzy uczenie maszynowe składa się z przedmiotu obserwacji (<strong>zbiór treningowy</strong>), przyrządy obserwacji (<strong>algorytm uczący</strong>) i końcowej reprezentacji (<strong>model statystyczny</strong>). Zestawienie tych trzech elementów prezentujemy tu w postaci szemranego i barokowego diagramu uczenia maszynowego, ekstrawagancko nazwanego nooskopem<a href="#nooscope-ref-07-bottom" id="nooscope-ref-07-top" class="nooscope-reference-num ai-scroll-to" data-toggle="tooltip" data-html="true" data-original-title="Zastosowanie analogii wizualnej ma na celu również to, by uchwycić zanikające rozróżnienie pomiędzy obrazem a logiką, reprezentacją i wnioskowaniem, w technicznej konstrukcji SI. Modele statystyczne uczenia maszynowego są reprezentacjami operacyjnymi (w rozumieniu takim jak obrazy operacyjne u Haruna Farockiego)."><sup>7</sup></a>. By trzymać się analogii z przyrządami optycznymi: przepływ informacji w uczeniu maszynowym jest jak promień światła wysyłany przez dane treningowe, skompresowany przez algorytm, poddany dyfrakcji i skierowany w stronę świata przez soczewkę modelu statystycznego.</p>
                                <p>Diagram nooskopu dąży do tego, by zilustrować dwie strony uczenia maszynowego za jednym zamachem – <strong>to, jak działa, i to, jak zawodzi</strong> – przez wyliczenie jego głównych składników, jak również ukazanie szerokiego zakresu błędów, ograniczeń, przybliżeń, uprzedzeń, usterek, fałszywych rozumowań i słabości, które są wpisane w ten paradygmat<a href="#nooscope-ref-08-bottom" id="nooscope-ref-08-top" class="nooscope-reference-num ai-scroll-to" data-toggle="tooltip" data-html="true" data-original-title="O systematycznym studium logicznych ograniczeń uczenia maszynowego zob. Momin Mailk, „A Hierarchy of Limitations in Machine Learning.’ Arxiv preprint, 2020. https://arxiv.org/abs/2002.05193"><sup>8</sup></a>. Ów podwójny cel podkreśla, że SI nie jest monolitycznym wzorcem racjonalności, ale szemraną architekturą, stworzoną przez zaadaptowanie różnych technik i trików. Poza tym granice SI nie są tylko techniczne, są wybrukowane ludzkimi uprzedzeniami. Na diagramie nooskopu podstawowe komponenty uczenia maszynowego przedstawione są w centrum, <strong>ludzkie uprzedzenia</strong> i interwencje są po lewej, <strong>błędy systematyczne</strong> i ograniczenia techniczne – po prawej stronie. Soczewki symbolizują błędy i przybliżenia, reprezentują kompresję i zniekształcenie przepływu informacji. Całkowity błąd uczenia maszynowego jest reprezentowany przez środkową soczewkę modelu statystycznego, w której dyfrakcji ulega postrzeganie świata.</p>
                                <p>Ograniczenia SI są dziś dostrzegane dzięki dyskusji o błędzie systematycznym – wzmocnieniu przez algorytmy dyskryminacji ze względu na płeć, rasę, sprawność fizyczną i klasę społeczną. W przypadku uczenia maszynowego konieczne jest rozróżnienie błędu historycznego, błędu zbioru danych i błędu algorytmu, z których każdy występuje na innym etapie przepływu informacji<a href="#nooscope-ref-09-bottom" id="nooscope-ref-09-top" class="nooscope-reference-num ai-scroll-to" data-toggle="tooltip" data-html="true" data-original-title="Na temat bardziej szczegółowej listy błędów SI zob. John Guttag and Harini Suresh, „A Framework for Understanding Unintended Consequences of Machine Learning.” Arxiv preprint, 2019. https://arxiv.org/abs/1901.10002 Zob. także: Aram Galstyan, Kristin Lerman, Ninareh Mehrabi, Fred Morstatter i Nripsuta Saxena, „A Survey on Bias and Fairness in Machine Learning.” Arxiv preprint, 2019. https://arxiv.org/abs/1908.09635 "><sup>9</sup></a>. <strong>Historyczna stronniczość</strong> (albo stronniczość świata) daje się dostrzec w społeczeństwie już przed interwencją technologii. Niemniej naturalizacja tej stronniczości, to znaczy wcielenie po cichu nierówności w neutralną z pozoru technologię, jest sama w sobie szkodliwa<a href="#nooscope-ref-10-bottom" id="nooscope-ref-10-top" class="nooscope-reference-num ai-scroll-to" data-toggle="tooltip" data-html="true" data-original-title="Virginia Eubanks, &lt;cite&gt;Automating Inequality&lt;/cite&gt;. New York: St. Martin’s Press, 2018. Zob. także: Kate Crawford, „The Trouble with Bias.” Keynote lecture, Conference on Neural Information Processing Systems, 2017."><sup>10</sup></a>. Parafrazując Michelle Alexander, Ruha Benjamin nazywa to Nowym Jimem Kodem<a href="#nooscope-translator-ref-03-bottom" id="nooscope-translator-ref-03-top" class="nooscope-reference-asterisk ai-scroll-to" data-toggle="tooltip" data-html="true" data-original-title="Za Wikipedią: Prawa Jima Crowa (ang. &lt;em&gt;Jim Crow laws&lt;/em&gt;) — regulacje wprowadzane głównie w południowych stanach Ameryki po wojnie secesyjnej. Miały za zadanie ograniczenie praw byłych czarnoskórych niewolników oraz pogłębianie separacji między białą a czarną ludnością w tych stanach. Do tego faktu historycznego odnosi się Michelle Alexander w książce &lt;cite&gt;The New Jim Crow: Mass Incarceration in the Age of Colorblindness&lt;/cite&gt; — przyp. tłum.">*</a>: <q>przyjęcie nowych technologii, które odbijają i reprodukują istniejące nierówności, a które są przedstawiane i postrzegane jako bardziej obiektywne czy bardziej postępowe niż dyskryminacyjne systemy z poprzedniej epoki</q><a href="#nooscope-ref-11-bottom" id="nooscope-ref-11-top" class="nooscope-reference-num ai-scroll-to" data-toggle="tooltip" data-html="true" data-original-title="Ruha Benjamin, &lt;cite&gt;Race After Technology: Abolitionist Tools for the New Jim Code&lt;/cite&gt;. Cambridge, UK: Polity, 2019, 5."><sup>11</sup></a>. <strong>Błąd systematyczny</strong> danych pojawia się w zbiorze podczas przygotowywania danych treningowych przez pracowników. Najdelikatniejsza część tego procesu to oznaczanie danych, w czasie którego stare, konserwatywne taksonomie mogą dawać zniekształcony obraz świata, przekłamywać zróżnicowanie społeczne i wyostrzać społeczne hierarchie (zobacz niżej przykład ImageNetu).</p>
                                <p><strong>Stronniczość algorytmu</strong> (znana też jako błąd maszynowy, błąd systematyczny albo obciążenie modelu, szczególnie istotne w diagramie nooskopu) wzmacnia jeszcze stronniczość historyczną i stronniczość zbioru danych za sprawą algorytmów uczenia maszynowego. Problem stronniczości wyrasta przede wszystkim z tego, że algorytmy uczenia maszynowego są jednymi z najbardziej skutecznych narzędzi <strong>kompresji danych</strong>, co rodzi problemy z dokładnością, dyfrakcją i utratą informacji<a href="#nooscope-ref-12-bottom" id="nooscope-ref-12-top" class="nooscope-reference-num ai-scroll-to" data-toggle="tooltip" data-html="true" data-original-title="Informatycy przekonują, że SI jest zagadnieniem z dziedziny &lt;em&gt;przetwarzania sygnałów&lt;/em&gt;, a konkretnie z poddziedziny &lt;em&gt;kompresji danych&lt;/em&gt;."><sup>12</sup></a>. Od najdawniejszych czasów algorytm był procedurą natury ekonomicznej, zaprojektowaną po to, by osiągnąć rezultat w jak najmniejszej liczbie kroków i przy zużyciu jak najmniejszej ilości zasobów: czasu, energii i pracy<a href="#nooscope-ref-13-bottom" id="nooscope-ref-13-top" class="nooscope-reference-num ai-scroll-to" data-toggle="tooltip" data-html="true" data-original-title="Matteo Pasquinelli, &lt;cite&gt;The Eye of the Master&lt;/cite&gt;. London: Verso, w przygotowaniu."><sup>13</sup></a>. W wyścigu zbrojeń między firmami SI wciąż chodzi o znalezienie najprostszych i najszybszych algorytmów, dzięki którym można spieniężać dane. Chociaż kompresja informacji wytwarza maksymalną stopę zwrotu dla korporacyjnej SI, to ze społecznego punktu widzenia jest źródłem dyskryminacji i utraty różnorodności kulturowej.</p>
                                <p>Tak jak społeczne konsekwencje SI są powszechnie ujmowane jako zjawisko stronniczości, tak jej techniczne ograniczenia są znane jako problem <strong>czarnej skrzynki</strong>. Efekt czarnej skrzynki to zjawisko faktycznie występujące w głębokich sieciach neuronowych (które filtrują informację tak bardzo, że nie da się odtworzyć ich łańcucha rozumowania), ale stało się ono utartą wymówką na rzecz opinii, że systemy SI są nie tylko tajemnicze i nieprzeniknione, ale wręcz „pozaludzkie” i że nie poddają się kontroli<a href="#nooscope-ref-14-bottom" id="nooscope-ref-14-top" class="nooscope-reference-num ai-scroll-to" data-toggle="tooltip" data-html="true" data-original-title='Projekty takie jak między innymi wytłumaczalna sztuczna inteligencja czy interpretowalne uczenie głębokie i mapy cieplne udowodniły, że przebicie się do "czarnej skrzynki" uczenia maszynowego jest możliwe. Niemniej jednak pełna interpretowalność i wytłumaczalność modeli statystycznych uczenia maszynowego pozostaje mitem. Zob. Zacharay Lipton, „The Mythos of Model Interpretability.” ArXiv preprint, 2016. https://arxiv.org/abs/1606.03490'><sup>14</sup></a>. Efekt czarnej skrzynki to część natury każdego eksperymentalnego urządzenia na wczesnym etapie jego rozwoju (już wspomnieliśmy, działanie maszyny parowej pozostawało przez pewien czas zagadką, nawet po tym, jak pomyślnie przeszła testy). Prawdziwym problemem jest retoryka czarnej skrzynki, bliska uczuciom zakorzenionym w teoriach spiskowych, w których SI to tajemna moc, której nie da się poznać, zgłębić ani politycznie kontrolować.</p>
                                <ul class="nooscope-translator-reference-list list-unstyled">
                                    <li class="nooscope-translator-reference-list-item">
                                        <div class="nooscope-translator-reference d-flex flex-row">
                                            <label id="nooscope-translator-ref-03-bottom" class="nooscope-translator-reference-asterisk small mr-1 mr-sm-1 mr-md-1 mr-lg-1 mr-xl-1">
                                                <a href="#nooscope-translator-ref-03-top" class="ai-scroll-to">*</a>
                                            </label>
                                            <p class="nooscope-translator-reference-desc small">Za Wikipedią: Prawa Jima Crowa (ang. <em>Jim Crow laws</em>) — regulacje wprowadzane głównie w południowych stanach Ameryki po wojnie secesyjnej. Miały za zadanie ograniczenie praw byłych czarnoskórych niewolników oraz pogłębianie separacji między białą a czarną ludnością w tych stanach. Do tego faktu historycznego odnosi się Michelle Alexander w książce <cite>The New Jim Crow: Mass Incarceration in the Age of Colorblindness</cite> — przyp. tłum.</p>
                                        </div>
                                    </li>
                                </ul>
                            </section>

                            <section>
                                <h2>3. Zbiór treningowy: społeczne źródła inteligencji maszynowej</h2>
                                <p>Masowa cyfryzacja, która rozszerzała swój zasięg wraz z internetem w latach dziewięćdziesiątych i rozrosła się wraz z centrami danych w pierwszej dekadzie XXI wieku, udostępniła ogromne zasoby danych, które po raz pierwszy w historii stały się darmowe i były nieuregulowane prawnie. Reżim <em>ekstraktywizmu wiedzy</em> (znany wówczas jako Big Data) stopniowo zaczął wykorzystywać bardzo wydajne algorytmy do wydobywania informacji z ogólnodostępnych źródeł danych, głównie po to, by przewidywać zachowania konsumentów i sprzedawać reklamy. Ekonomia wiedzy przekształciła się w nową formę kapitalizmu, nazywanego przez różnych autorów <em>kapitalizmem kognitywnym</em>, a później <em>kapitalizmem nadzoru</em><a href="#nooscope-ref-15-bottom" id="nooscope-ref-15-top" class="nooscope-reference-num ai-scroll-to" data-toggle="tooltip" data-html="true" data-original-title="A. Corsani, B. Paulré, C. Vercellone, J.M. Monnier, M. Lazzarato, P. Dieuaide and Y. Moulier-Boutang, „Le Capitalisme cognitif comme sortie de la crise du capitalisme industriel. Un programme de recherché”, Paris: Laboratoire Isys Matisse, Maison des Sciences Economiques, 2004. See also: Zuboff, Shoshana, &lt;cite&gt;The Age of Surveillance Capitalism: The Fight for a Human Future at the New Frontier of Power&lt;/cite&gt;. London: Profile Books, 2019."><sup>15</sup></a>. Zalew informacji w internecie, ogromne centra danych, szybsze mikroprocesory i algorytmy służące do kompresji danych – wszystko to położyło fundamenty pod powstanie monopoli SI w XXI wieku.</p>
                                <p>Jakiego rodzaju kulturowym i technicznym przedmiotem jest zbiór danych stanowiący źródło dla SI? Jakość <strong>danych treningowych</strong> to najważniejszy czynnik wpływający na tak zwaną inteligencję wydobywaną przez algorytmy uczenia maszynowego. Należy brać pod uwagę pewien istotny punkt widzenia, by zrozumieć SI jako nooskop. Dane to pierwsze i najważniejsze źródło wartości i informacji. Drugie to algorytmy – to właśnie one są maszynami, które wyliczają model na podstawie wartości i informacji. Dane treningowe nie są jednak nigdy surowe, niezależne ani bezstronne (już same w sobie są „algorytmiczne”)<a href="#nooscope-ref-16-bottom" id="nooscope-ref-16-top" class="nooscope-reference-num ai-scroll-to" data-toggle="tooltip" data-html="true" data-original-title="Lisa Gitelman (ed.), &lt;cite&gt;Raw Data is an Oxymoron&lt;/cite&gt;, Cambridge, MA: MIT Press, 2013."><sup>16</sup></a>. Przycinanie, formatowanie i edycja zbiorów treningowych to przedsięwzięcie pracochłonne i delikatne, prawdopodobnie istotniejsze dla końcowego rezultatu niż parametry techniczne, które kontrolują algorytm uczący. Akt wyboru tego, a nie innego źródła danych to głęboki znak ludzkiej interwencji w dziedzinę sztucznych umysłów.</p>
                                <figure class="ai-img-wrap text-center mt-5 mt-sm-5 mt-md-5 mt-lg-5 mt-xl-5">
                                    <img class="img-fluid" src="img/Nooscope_02_Data_PL.svg" alt="Dane">
                                </figure>
                                <p>Zbiór treningowy to <strong>twór kulturowy</strong>, a nie tylko techniczny. Składa się zwykle z danych wejściowych, które są połączone z idealnymi danymi wyjściowymi, na przykład obrazki z ich opisami, które nazywane są także etykietami lub metadanymi<a href="#nooscope-ref-17-bottom" id="nooscope-ref-17-top" class="nooscope-reference-num ai-scroll-to" data-toggle="tooltip" data-html="true" data-original-title="In supervised learning. Also self-supervised learning maintains forms of human intervention."><sup>17</sup></a>. Kanonicznym przykładem może być kolekcja muzealna wraz z jej archiwum, w którym dzieła sztuki są uporządkowane według metadanych, takich jak autor, rok, technika itp. Proces semiotyczny przypisania nazwy lub kategorii do obrazu nigdy nie jest bezstronny; ten proces zostawia kolejny wyraźny ślad wpływu człowieka na ostateczny wynik poznania maszynowego. Zbiór danych treningowych dla uczenia maszynowego powstaje zazwyczaj w następujących krokach:</p>
                                <ol>
                                    <li>Produkcja – praca lub zjawiska, które wytwarzają informację;</li>
                                    <li>Uchwycenie – zakodowanie informacji do formatu danych przy pomocy jakiegoś narzędzia;</li>
                                    <li>Formatowanie – uporządkowanie danych w zbiór danych;</li>
                                    <li>Etykietowanie – w uczeniu nadzorowanym zaklasyfikowanie danych do kategorii (metadanych).</li>
                                </ol>
                                <p>Inteligencja maszynowa jest trenowana na ogromnych zbiorach danych, gromadzonych w sposób, który nie jest ani technicznie, ani społecznie bezstronny. Surowe dane nie istnieją, ponieważ są zależne od ludzkiej pracy, danych osobistych i zachowań społecznych, które kumulują się w długich okresach czasu, w rozległych sieciach i z użyciem kontrowersyjnych taksonomii<a href="#nooscope-ref-18-bottom" id="nooscope-ref-18-top" class="nooscope-reference-num ai-scroll-to" data-toggle="tooltip" data-html="true" data-original-title="Na temat taksonomii jako formy wiedzy i siły zob. Michel Foucault, &lt;cite&gt;The Order of Things&lt;/cite&gt;. London: Routledge, 2005."><sup>18</sup></a>. Najważniejsze zbiory danych treningowych dla uczenia maszynowego (MNIST, ImageNet, Labelled Faces in the Wild) mają swój początek w korporacjach, na uczelniach i w agencjach wojskowych globalnej Północy. Przy bliższym spojrzeniu można wyraźnie dostrzec podział pracy, który wdziera się do globalnego Południa za pomocą platform crowdsourcingowych, wykorzystywanych do edycji i walidacji danych<a href="#nooscope-ref-19-bottom" id="nooscope-ref-19-top" class="nooscope-reference-num ai-scroll-to" data-toggle="tooltip" data-html="true" data-original-title='Na przykład stworzony przez Amazon Mechaniczny Turek, cynicznie nazwany przez Jeffa Bezosa "sztuczną sztuczną inteligencją". Zob. Jason Pontin, „Artificial Intelligence, With Help from the Humans.” &lt;cite&gt;The New York Times,&lt;/cite&gt; 25 marca 2007.'><sup>19</sup></a>. Przypowieść o zbiorach <strong>ImageNetu</strong> pokazuje problemy wielu zbiorów danych SI. ImageNet to zbiór treningowy dla uczenia głębokiego, który stał się <i>de facto</i> głównym punktem odniesienia dla algorytmów rozpoznawania obrazów: rewolucja uczenia głębokiego zaczęła się, kiedy Alex Krizhevsky, Ilya Sutskever i Geoffrey Hinton wygrali doroczny konkurs ImageNetu swoją neuronową siecią konwolucyjną AlexNet<a href="#nooscope-ref-20-bottom" id="nooscope-ref-20-top" class="nooscope-reference-num ai-scroll-to" data-toggle="tooltip" data-html="true" data-original-title="Chociaż architektura konwolucyjna sięga czasów prac Yanna LeCunna pod koniec lat osiemdziesiątych, uczenie głębokie zaczęło się od tego artykułu: Geoffrey Hinton, Alex Krizhevsky i Ilya Sutskever, „ImageNet Classification with Deep Convolutional Neural Networks.” &lt;cite&gt;Communications of the ACM&lt;/cite&gt; 60(6), 2017."><sup>20</sup></a>. ImageNet został uruchomiony przez informatyka Fei-Fei Li w 2006 roku<a href="#nooscope-ref-21-bottom" id="nooscope-ref-21-top" class="nooscope-reference-num ai-scroll-to" data-toggle="tooltip" data-html="true" data-original-title="Dla przystępnych (ale niezbyt krytycznych) uwag na temat rozwoju ImageNetu zob. Melanie Mitchell, &lt;cite&gt;Artificial Intelligence: A Guide for Thinking Humans&lt;/cite&gt;. London: Penguin, 2019."><sup>21</sup></a>. Fei-Fei Li miał trzy intuicje dotyczące tego, jak zbudować wiarygodny zbiór danych do rozpoznawania obrazów. Po pierwsze, ściągnąć miliony darmowych obrazów z serwisów sieciowych takich jak Flickr i Google. Po drugie, zaadaptować komputacyjną taksonomię <strong>WordNet</strong> do etykiet obrazów<a href="#nooscope-ref-22-bottom" id="nooscope-ref-22-top" class="nooscope-reference-num ai-scroll-to" data-toggle="tooltip" data-html="true" data-original-title="WordNet jest &lt;q&gt;leksykalną bazdą danych relacji semantycznych między słowami&lt;/q&gt;, która została zapoczątkowana przez George'a Armitage'a na Uniwersytecie Princeton w 1985 roku. Zapewnia ona ścisłą drzewiastą strukturę definicji."><sup>22</sup></a>. Po trzecie, przekazać pracę polegającą na nadawaniu etykiet milionom obrazów przy pomocy platformy crowdsourcingowej Amazon Mechanical Turk. Na szarym końcu (oraz na końcu taśmy produkcyjnej) anonimowi robotnicy z całego świata dostawali kilka centów zapłaty za wykonanie zadania – przypisanie obrazom setek etykiet na minutę zgodnie z taksonomią WordNetu. W wyniku ich pracy powstał kontrowersyjny konstrukt kulturowy. Zajmująca się SI uczona Kate Crawford i artysta Trevor Paglen ujawnili osad rasistowskich i seksistowskich kategorii w taksonomii ImageNetu (chociażby zakres kategorii „porażka, nieudacznik, przegryw, osoba przegrana” dla stu dowolnych zdjęć ludzi)<a href="#nooscope-ref-23-bottom" id="nooscope-ref-23-top" class="nooscope-reference-num ai-scroll-to" data-toggle="tooltip" data-html="true" data-original-title="Kate Crawford i Trevor Paglen, „Excavating AI: The Politics of Training Sets for Machine Learning.” 19 września 2019. https://excavating.ai"><sup>23</sup></a>.</p>
                                <p>Żarłoczny ekstraktywizm danych dla SI wywołał niespodziewaną reakcję w kulturze cyfrowej: na początku XXI wieku Lawrence Lessig nie mógł przewidzieć, że wielkie repozytorium obrazów dostępnych online na licencji <strong>Creative Commons</strong> dziesięć lat później stanie się nieuregulowanym prawnie zasobem dla technologii rozpoznawania twarzy służących nadzorowi. W podobny sposób dane osobiste są stale wcielane w prywatne zbiory danych dla uczenia maszynowego. W 2019 artysta i badacz SI Adam Harvey po raz pierwszy ujawnił odbywające się bez pytania o zgodę użycie prywatnych zdjęć w zbiorach treningowych do rozpoznawania twarzy. Rewelacje Harveya skłoniły Uniwersytet Stanforda, Uniwersytet Duke i Microsoft do wycofania swoich zbiorów danych w atmosferze <strong>wielkiego skandalu</strong><a href="#nooscope-ref-24-bottom" id="nooscope-ref-24-top" class="nooscope-reference-num ai-scroll-to" data-toggle="tooltip" data-html="true" data-original-title="Adam Harvey i Jules LaPlace, Megapixel project, 2019. https://megapixels.cc/about/ i: Madhumita Murgia, „Who's Using Your Face? The Ugly Truth About Facial Recognition.” &lt;cite&gt;Financial Times&lt;/cite&gt;, 19 kwietnia 2019."><sup>24</sup></a>. Dostępne online zbiory danych zmuszają do zadawania pytań o suwerenność danych i o prawa obywatelskie, a reakcja tradycyjnych instytucji jest w tej sprawie bardzo powolna (zobacz europejskie Ogólne rozporządzenie o ochronie danych)<a href="#nooscope-ref-25-bottom" id="nooscope-ref-25-top" class="nooscope-reference-num ai-scroll-to" data-toggle="tooltip" data-html="true" data-original-title="Ogólne rozporządzenie o ochronie danych, które zostało przyjęte przez Parlament Europejski w maju 2018 jest mimo wszystko krokiem naprzód w porównaniu do wciąż trwającego braku regulacji w Stanach Zjednoczonych."><sup>25</sup></a>. O ile 2012 to rok, w którym zaczęła się rewolucja uczenia głębokiego, o tyle 2019 jest rokiem, w którym odkryto, że jego źródła są zatrute.</p>
                                <figure class="ai-img-wrap text-center mt-5 mt-sm-5 mt-md-5 mt-lg-5 mt-xl-5">
                                    <img class="img-fluid" src="img/Nooscope-03.gif" alt="Wzorce kombinatoryczne i pismo kufickie, zwój z Topkapi, ok. 1500, Iran.">
                                    <figcaption class="nooscope-reference-fig-desc small mt-3 mt-sm-3 mt-md-3 mt-lg-3 mt-xl-3">Wzorce kombinatoryczne i pismo kufickie, zwój z Topkapi, ok. 1500, Iran.</figcaption>
                                </figure>
                            </section>

                            <section>
                                <h2>4. Historia SI jako automatyzacji postrzegania</h2>
                                <p>Potrzeba odczarowania SI (przynajmniej z technicznego punktu widzenia) została zauważona również w świecie korporacji. Szef Facebook AI i ojciec chrzestny konwolucyjnych sieci neuronowych Yann LeCun powtarza, że współczesne systemy SI to wyrafinowane wersje nie zdolności poznawczych, ale percepcji. Podobnie diagram Nooskopu eksponuje szkielet czarnej skrzynki SI i pokazuje, że SI nie jest myślącą maszyną, tylko algorytmem, który <strong>rozpoznaje wzorce</strong>. Skoro wspomnieliśmy o rozpoznawaniu wzorców, to musimy rozwinąć kilka kwestii. Czym w ogóle jest wzorzec? Czy wzorzec jest bytem wyłącznie wizualnym? Co to znaczy odczytywać zachowania społeczne jako wzorce? Czy rozpoznawanie wzorców to wyczerpująca definicja inteligencji? Najprawdopodobniej nie. Aby wyjaśnić te kwestie, dobrze będzie przedsięwziąć krótką wyprawę do archeologii SI.</p>
                                <p>Archetypem maszyny do rozpoznawania obrazu jest <strong>perceptron</strong> Franka Rosenblatta. Został on wynaleziony w 1957 roku w Laboratorium Aeronautycznym Cornell w Buffalo w stanie Nowy Jork, a jego nazwa to skrót od „automat percepcyjny i rozpoznający” (Perceiving and Recognizing Automaton)<a href="#nooscope-ref-26-bottom" id="nooscope-ref-26-top" class="nooscope-reference-num ai-scroll-to" data-toggle="tooltip" data-html="true" data-original-title="Frank Rosenblatt, „The Perceptron: A Perceiving and Recognizing Automaton.” Cornell Aeronautical Laboratory Report 85-460-1, 1957."><sup>26</sup></a>. Dysponując matrycą składającą się z 20×20 fotoreceptorów, perceptron może nauczyć się rozpoznawać proste litery. Wzorzec wizualny zostaje zapisany jako ślad na sieci sztucznych neuronów, które wraz z pojawianiem się podobnych obrazów przesyłają impuls i w efekcie aktywują pojedynczy neuron na wyjściu. Neuron na wyjściu przesyła 1=prawda, jeśli dany obraz został rozpoznany, lub 0=fałsz, jeśli obraz nie został rozpoznany.</p>
                                <p>Automatyzacja postrzegania, rozumiana jako wizualny montaż pikseli na obliczeniowej taśmie produkcyjnej, była pierwotnie wpisana implicite w wizję sztucznych sieci neuronowych McCullocha i Pittsa<a href="#nooscope-ref-27-bottom" id="nooscope-ref-27-top" class="nooscope-reference-num ai-scroll-to" data-toggle="tooltip" data-html="true" data-original-title="Warren McCulloch i Walter Pitts, „How We Know Universals: The Perception of Auditory and Visual Forms.” &lt;cite&gt;The Bulletin of Mathematical Biophysics&lt;/cite&gt; 9(3): 1947."><sup>27</sup></a>. Kiedy algorytm rozpoznawania schematów wizualnych przetrwał „zimę SI” i udowodnił swoją wydajność pod koniec pierwszej dekady XXI wieku, znalazł zastosowanie również w niewizualnych zbiorach danych, co właściwie zapoczątkowało wiek uczenia głębokiego (użycie techniki rozpoznawania wzorców do wszystkich rodzajów danych, nie tylko wizualnych). Dziś w przypadku samochodów autonomicznych wzorce, jakie musi rozpoznać maszyna, to obiekty w scenariuszu drogowym. W przypadku automatycznego tłumaczenia rozpoznawane wzorce to najczęstsze sekwencje wyrazów w tekstach dwujęzycznych. Z perspektywy numerycznej wszystkie rzeczy takie jak obraz, ruch, kształt, styl i decyzja etyczna, niezależnie od ich złożoności, można opisać jako rozkład statystyczny wzorca. W tym sensie rozpoznawanie wzorców stało się nową <strong>techniką kulturową</strong> stosowaną w różnych dziedzinach. Na potrzeby wyjaśnienia nooskop został opisany jako maszyna operująca w trzech modalnościach: <strong>trenowanie</strong>, <strong>klasyfikacja</strong> i <strong>predykcja</strong>. Bardziej intuicyjnie można nazwać te modalności: wydobywanie wzorców, rozpoznawanie wzorców, generowanie wzorców. </p>
                                <p>Perceptron Rosenblatta był pierwszym algorytmem, który wytyczył drogę uczeniu maszynowemu, jakie znamy dzisiaj. Zanim ugruntowało się określenie „informatyka”, dziedzina ta była nazywana „geometrią obliczeniową”, a przez samego Rosenblatta – „konekcjonizmem”. Zadaniem tamtych sieci neuronowych było obliczanie inferencji statystycznej. Sieć neuronowa nie oblicza samego wzorca, tylko jego <strong>rozkład statystyczny</strong>. Prześlizgując się zaledwie po powierzchni antropomorficznego marketingu SI, można znaleźć jeszcze jeden techniczny i kulturowy obiekt, który warto przebadać: <strong>model statystyczny</strong>. Czym jest model statystyczny w uczeniu maszynowym? Jak się go oblicza? Jaka jest relacja między modelem statystycznym a ludzkim poznaniem? To kluczowe kwestie, które należy wyjaśnić. W ramach pracy demistyfikacyjnej, jaką należy wykonać (również po to, by pozbyć się pewnych naiwnych pytań), dobrze byłoby przeformułować oklepane pytanie „Czy maszyna może myśleć?” na bardziej rozsądne z punktu widzenia teorii pytania: „Czy model statystyczny może myśleć?”, „Czy model statystyczny może rozwinąć świadomość?” itp.</p>
                            </section>

                            <section>
                                <h2>5. Algorytm uczący: kompresowanie świata do modelu statystycznego</h2>
                                <p>Algorytmy SI często przywoływane są jako alchemiczne formuły zdolne do destylowania „pozaludzkich” form inteligencji. Co jednak tak naprawdę robią algorytmy uczenia maszynowego? Niewiele osób, także wśród zwolenników ogólnej sztucznej inteligencji<a href="#nooscope-translator-ref-04-bottom" id="nooscope-translator-ref-04-top" class="nooscope-reference-asterisk ai-scroll-to" data-toggle="tooltip" data-html="true" data-original-title="ang. &lt;em&gt;&lt;abbr&gt;AGI&lt;/abbr&gt; – Artificial General Intelligence&lt;/em&gt; — przyp. tłum.">*</a>, zadaje sobie to pytanie. Algorytm to nazwa procesu, w którym maszyna wykonuje obliczenia. Rezultatem takich maszynowych procesów jest model statystyczny (a dokładniej coś, co nosi nazwę „algorytmicznego modelu statystycznego”). W środowisku programistów termin „algorytm” jest coraz częściej zastępowany pojęciem „model”. Owo terminologiczne pomieszanie wynika z faktu, że statystyczny model nie istnieje niezależnie od algorytmu: w jakiś sposób model statystyczny istnieje w algorytmie jako pamięć rozproszona w postaci jego parametrów. Z tego samego powodu w zasadzie nie da się zwizualizować algorytmicznego modelu statystycznego, tak jak robi się to z prostymi funkcjami matematycznymi. Mimo to warto podjąć wyzwanie.</p>
                                <p>W uczeniu maszynowym mamy do czynienia z różnymi <strong>architekturami algorytmów</strong>: prosty perceptron, głęboka sieć neuronowa, maszyna wektorów nośnych, sieć bayesowska, łańcuch Markowa, autoencoder, maszyna Boltzmanna itp. Każda z tych architektur posiada inną historię (często zakorzenioną w agencjach wojskowych i korporacjach globalnej Północy). Sztuczne sieci neuronowe były na początku prostymi strukturami obliczeniowymi, które ewoluowały do skomplikowanych struktur, kontrolowanych przez miliony <strong>parametrów</strong> wyrażanych przy pomocy kilku <strong>hiperparametrów</strong><a href="#nooscope-ref-28-bottom" id="nooscope-ref-28-top" class="nooscope-reference-num ai-scroll-to" data-toggle="tooltip" data-html="true" data-original-title="Parametry modelu wyuczone z danych nazywa się &lt;em&gt;parametrami&lt;/em&gt;, natomiast te parametry, które nie są wyuczone z danych, lecz ustawione ręcznie, nazywa się &lt;em&gt;hiperparametrami&lt;/em&gt; (określają one ilość i właściwości parametrów)."><sup>28</sup></a>. Dla przykładu, konwolucyjne sieci neuronowe są opisywane przez ograniczony zestaw hiperparametrów (liczby warstw, ilości neuronów na każdej warstwie, rodzaju połączenia, zachowania neuronów itp.), które rzutują kompleksową topologię tysięcy sztucznych neuronów wraz z milionami parametrów. Algorytm zaczyna jako czysta karta i – w trakcie procesu nazywanego trenowaniem albo „uczeniem się z danych” – dostosowuje swoje parametry, póki nie uzyska dobrej reprezentacji danych wejściowych. W rozpoznawaniu obrazów, jak wykazano, proces obliczeniowy milionów parametrów dąży do rozwiązania w prostej binarnej danej wyjściowej: 1=prawda, przedstawiony obraz został rozpoznany, albo 0=fałsz, przedstawiony obraz nie został rozpoznany<a href="#nooscope-ref-29-bottom" id="nooscope-ref-29-top" class="nooscope-reference-num ai-scroll-to" data-toggle="tooltip" data-html="true" data-original-title="Rozwiązanie to może być także wyrażone procentowo i przyjmować wartość pomiędzy 0 a 1."><sup>29</sup></a>.</p>
                                <figure class="ai-img-wrap text-center mt-5 mt-sm-5 mt-md-5 mt-lg-5 mt-xl-5">
                                    <img class="img-fluid" src="img/Nooscope_04_Architecture.svg" alt="Źródło: https://www.asimovinstitute.org/neural-network-zoo">
                                    <figcaption class="nooscope-reference-fig-desc small mt-3 mt-sm-3 mt-md-3 mt-lg-3 mt-xl-3">Źródło:
                                        <a href="https://www.asimovinstitute.org/neural-network-zoo" target="_blank">www.asimovinstitute.org/neural-network-zoo</a></figcaption>
                                </figure>
                                <p>Żeby w przystępny sposób wyjaśnić związek pomiędzy algorytmem a modelem, spójrzmy na kompleksowy algorytm Inception v3, oparty na głębokiej konwolucyjnej sieci neuronowej służącej do rozpoznawania obrazów, zaprojektowany przez Google i trenowany na zbiorze danych pochodzących z ImageNetu. Mówi się, że Inception v3 posiada dokładność na poziomie 78% w identyfikowaniu poprawnych opisów dla obrazów, jednak w tym wypadku wydajność „maszynowej inteligencji” może być również mierzona stosunkiem rozmiaru danych treningowych do rozmiaru algorytmu trenującego (lub modelu). ImageNet zawiera 14 milionów obrazów z przypisanymi opisami, które zajmują mniej więcej 150 GB pamięci. Tymczasem, Inception v3, którego zadaniem jest reprezentacja informacji zawartych w ImageNet, waży jedynie 92 MB. Stosunek kompresji pomiędzy zbiorem treningowym i modelem częściowo opisuje również poziom dyfrakcji informacji. Tabela z dokumentacji biblioteki Keras zestawia ze sobą te wartości (liczbę parametrów, głębokość warstwy, wymiar pliku i dokładność) dla głównych modeli rozpoznawania obrazów<a href="#nooscope-ref-30-bottom" id="nooscope-ref-30-top" class="nooscope-reference-num ai-scroll-to" data-toggle="tooltip" data-html="true" data-original-title="https://keras.io/applications (dokumentacja poszczególnych modeli)."><sup>30</sup></a>. Jest to brutalny, ale efektywny sposób na pokazanie relacji między modelem a danymi po to, by zademonstrować, w jaki sposób „inteligencja” algorytmów jest mierzona i szacowana w społeczności programistów.</p>
                                <div class="frame">
                                    <h5>Dokumentacja poszczególnych modeli</h5>
                                    <figure>
                                        <table>
                                            <thead>
                                            <tr>
                                                <th class="first">Model</th>
                                                <th class="text-right">Rozmiar</th>
                                                <th class="text-right">Dokładność top-1</th>
                                                <th class="text-right">Dokładność top-5</th>
                                                <th class="text-right">Parametery</th>
                                                <th class="text-right">Liczba warstw</th>
                                            </tr>
                                            </thead>
                                            <tbody>
                                            <tr>
                                                <td>Xception</td>
                                                <td class="text-right">88 MB</td>
                                                <td class="text-right">0.790</td>
                                                <td class="text-right">0.945</td>
                                                <td class="text-right">22,910,480</td>
                                                <td class="text-right">126</td>
                                            </tr>
                                            <tr>
                                                <td>VGG16</td>
                                                <td class="text-right">528 MB</td>
                                                <td class="text-right">0.713</td>
                                                <td class="text-right">0.901</td>
                                                <td class="text-right">138,357,544</td>
                                                <td class="text-right">23</td>
                                            </tr>
                                            <tr>
                                                <td>VGG19</td>
                                                <td class="text-right">549 MB</td>
                                                <td class="text-right">0.713</td>
                                                <td class="text-right">0.900</td>
                                                <td class="text-right">143,667,240</td>
                                                <td class="text-right">26</td>
                                            </tr>
                                            <tr>
                                                <td>ResNet50</td>
                                                <td class="text-right">98 MB</td>
                                                <td class="text-right">0.749</td>
                                                <td class="text-right">0.921</td>
                                                <td class="text-right">25,636,712</td>
                                                <td class="text-right">-</td>
                                            </tr>
                                            <tr>
                                                <td>ResNet101</td>
                                                <td class="text-right">171 MB</td>
                                                <td class="text-right">0.764</td>
                                                <td class="text-right">0.928</td>
                                                <td class="text-right">44,707,176</td>
                                                <td class="text-right">-</td>
                                            </tr>
                                            <tr>
                                                <td>ResNet152</td>
                                                <td class="text-right">232 MB</td>
                                                <td class="text-right">0.766</td>
                                                <td class="text-right">0.931</td>
                                                <td class="text-right">60,419,944</td>
                                                <td class="text-right">-</td>
                                            </tr>
                                            <tr>
                                                <td>ResNet50V2</td>
                                                <td class="text-right">98 MB</td>
                                                <td class="text-right">0.760</td>
                                                <td class="text-right">0.930</td>
                                                <td class="text-right">25,613,800</td>
                                                <td class="text-right">-</td>
                                            </tr>
                                            <tr>
                                                <td>ResNet101V2</td>
                                                <td class="text-right">171 MB</td>
                                                <td class="text-right">0.772</td>
                                                <td class="text-right">0.938</td>
                                                <td class="text-right">44,675,560</td>
                                                <td class="text-right">-</td>
                                            </tr>
                                            <tr>
                                                <td>ResNet152V2</td>
                                                <td class="text-right">232 MB</td>
                                                <td class="text-right">0.780</td>
                                                <td class="text-right">0.942</td>
                                                <td class="text-right">60,380,648</td>
                                                <td class="text-right">-</td>
                                            </tr>
                                            <tr>
                                                <td>InceptionV3</td>
                                                <td class="text-right">92 MB</td>
                                                <td class="text-right">0.779</td>
                                                <td class="text-right">0.937</td>
                                                <td class="text-right">23,851,784</td>
                                                <td class="text-right">159</td>
                                            </tr>
                                            <tr>
                                                <td>InceptionResNetV2</td>
                                                <td class="text-right">215 MB</td>
                                                <td class="text-right">0.803</td>
                                                <td class="text-right">0.953</td>
                                                <td class="text-right">55,873,736</td>
                                                <td class="text-right">572</td>
                                            </tr>
                                            <tr>
                                                <td>MobileNet</td>
                                                <td class="text-right">16 MB</td>
                                                <td class="text-right">0.704</td>
                                                <td class="text-right">0.895</td>
                                                <td class="text-right">4,253,864</td>
                                                <td class="text-right">88</td>
                                            </tr>
                                            <tr>
                                                <td>MobileNetV2</td>
                                                <td class="text-right">14 MB</td>
                                                <td class="text-right">0.713</td>
                                                <td class="text-right">0.901</td>
                                                <td class="text-right">3,538,984</td>
                                                <td class="text-right">88</td>
                                            </tr>
                                            <tr>
                                                <td>DenseNet121</td>
                                                <td class="text-right">33 MB</td>
                                                <td class="text-right">0.750</td>
                                                <td class="text-right">0.923</td>
                                                <td class="text-right">8,062,504</td>
                                                <td class="text-right">121</td>
                                            </tr>
                                            <tr>
                                                <td>DenseNet169</td>
                                                <td class="text-right">57 MB</td>
                                                <td class="text-right">0.762</td>
                                                <td class="text-right">0.932</td>
                                                <td class="text-right">14,307,880</td>
                                                <td class="text-right">169</td>
                                            </tr>
                                            <tr>
                                                <td>DenseNet201</td>
                                                <td class="text-right">80 MB</td>
                                                <td class="text-right">0.773</td>
                                                <td class="text-right">0.936</td>
                                                <td class="text-right">20,242,984</td>
                                                <td class="text-right">201</td>
                                            </tr>
                                            <tr>
                                                <td>NASNetMobile</td>
                                                <td class="text-right">23 MB</td>
                                                <td class="text-right">0.744</td>
                                                <td class="text-right">0.919</td>
                                                <td class="text-right">5,326,716</td>
                                                <td class="text-right">-</td>
                                            </tr>
                                            <tr>
                                                <td>NASNetLarge</td>
                                                <td class="text-right">343 MB</td>
                                                <td class="text-right">0.825</td>
                                                <td class="text-right">0.960</td>
                                                <td class="text-right">88,949,818</td>
                                                <td class="text-right">-</td>
                                            </tr>
                                            </tbody>
                                        </table>
                                        <figcaption class="nooscope-reference-fig-desc small mt-3 mt-sm-3 mt-md-3 mt-lg-3 mt-xl-3 bottom_padding">Źródło:
                                            <a href="https://keras.io/applications" target="_blank">keras.io/applications</a></figcaption>
                                    </figure>
                                </div>
                                <p>Modele statystyczne od zawsze wpływały na kulturę i politykę. Nie pojawiły się dopiero wraz z uczeniem maszynowym – uczenie maszynowe jest jedynie nowym sposobem automatyzacji technik modelowania statystycznego. Kiedy Greta Thunberg ostrzega: „Słuchajcie nauki”, to jako uczennica dobra z matematyki ma na myśli: „Słuchajcie statystycznych modeli nauk o klimacie”. Bez statystycznych modeli nie ma nauk o klimacie; bez nauk o klimacie nie ma aktywizmu klimatycznego. Nauki o klimacie są dobrym przykładem, od którego warto zacząć, żeby zrozumieć modele statystyczne. Globalne ocieplenie wyliczono przez zebranie najpierw ogromnej ilości danych na temat temperatur na Ziemi z każdego dnia roku, a następnie zastosowano matematyczny model, który wyznacza krzywą zmienności temperatury z przeszłości, aby powstały w ten sposób wzorzec rzutować na przyszłość<a href="#nooscope-ref-31-bottom" id="nooscope-ref-31-top" class="nooscope-reference-num ai-scroll-to" data-toggle="tooltip" data-html="true" data-original-title="Paul Edwards, &lt;cite&gt;A Vast Machine: Computer Models, Climate Data, and The Politics of Global Warming&lt;/cite&gt;. Cambridge, MA:"><sup>31</sup></a>. Modele klimatyczne są artefaktami o naturze historycznej, testowanymi i omawianymi w <strong>społeczności naukowej</strong>, a dzisiaj również poza nią<a href="#nooscope-ref-32-bottom" id="nooscope-ref-32-top" class="nooscope-reference-num ai-scroll-to" data-toggle="tooltip" data-html="true" data-original-title="Zob. także &lt;cite&gt;Wspólny Model Ziemskiego Systemu Klimatycznego&lt;/cite&gt; (ang. &lt;cite&gt;Community Earth System Model&lt;/cite&gt; &lt;abbr&gt;(CESM)&lt;/abbr&gt;) tworzony od 1996 roku przez Narodowe Centrum Badań Atmosferycznych (&lt;abbr&gt;NCAR&lt;/abbr&gt;) w Bolder, Kolorado. Community Earth System Model to w pełni sprzężona symulacja numeryczna systemu Ziemi składająca się z atmosfery, oceanu, lodu, powierzchni lądu, obiegu węgla i innych elementów. &lt;abbr&gt;CESM&lt;/abbr&gt; zawiera model klimatyczny zapewniający najnowocześniejsze symulacje przeszłości, teraźniejszości i przyszłości Ziemi. http://www.cesm.ucar.edu"><sup>32</sup></a>. Modele maszynowe zaś pozostają niejawne i niedostępne dla szerszej publiczności. Biorąc pod uwagę to, jak wokół konstruktów matematycznych sztucznej inteligencji tworzą się mity i uprzedzenia społeczne, rzeczywiście zapoczątkowała ona erę <em>statystycznej fantastyki naukowej</em>. Nooskop jest projektorem w tym ogromnym statystycznym kinie.</p>
                                <ul class="nooscope-translator-reference-list list-unstyled">
                                    <li class="nooscope-translator-reference-list-item">
                                        <div class="nooscope-translator-reference d-flex flex-row">
                                            <label id="nooscope-translator-ref-04-bottom" class="nooscope-translator-reference-asterisk small mr-1 mr-sm-1 mr-md-1 mr-lg-1 mr-xl-1">
                                                <a href="#nooscope-translator-ref-04-top" class="ai-scroll-to">*</a>
                                            </label>
                                            <p class="nooscope-translator-reference-desc small">ang. <em><abbr>AGI</abbr> – Artificial General Intelligence</em> — przyp. tłum.</p>
                                        </div>
                                    </li>
                                </ul>
                            </section>

                            <section>
                                <h2>6. Wszystkie modele są błędne, ale niektóre są użyteczne</h2>
                                <p><q>Wszystkie modele są błędne, ale niektóre są użyteczne</q> – kanoniczne już twierdzenie brytyjskiego statystyka George’a Boxa od dawna ujmuje logiczne ograniczenia statystyki i uczenia maszynowego<a href="#nooscope-ref-33-bottom" id="nooscope-ref-33-top" class="nooscope-reference-num ai-scroll-to" data-toggle="tooltip" data-html="true" data-original-title="George Box, „Robustness in the Strategy of Scientific Model Building.” Technical Report #1954, Mathematics Research Center, University of Wisconsin-Madison, 1979."><sup>33</sup></a>. Jednakże ta maksyma często jest wykorzystywana w celu uprawomocnienia stronniczości zarówno korporacyjnej, jak i państwowej sztucznej inteligencji. Informatycy przekonują, że ludzkie poznanie odzwierciedla zdolność do wyodrębniania i aproksymacji wzorców. Czemu maszyny nie miałyby robić tego samego, skoro też aproksymują? W argumencie tym retorycznie powtórzone jest to, że „mapa nie jest terytorium”. Brzmi to sensownie. Należy jednak podkreślić, że sztuczna inteligencja jest mocno skompresowaną i zniekształconą mapą terytorium i że ta mapa, podobnie jak wiele form automatyzacji, nie poddaje się negocjacjom w sferze publicznej. Sztuczna inteligencja jest mapą terytorium bez społecznego dostępu i bez społecznej zgody<a href="#nooscope-ref-34-bottom" id="nooscope-ref-34-top" class="nooscope-reference-num ai-scroll-to" data-toggle="tooltip" data-html="true" data-original-title="Postkolonialne oraz poststrukturalistyczne szkoły antropologiczne i etnologiczne podkreślały, że nigdy nie istnieje terytorium &lt;i&gt;per se&lt;/i&gt;, ale zawsze występuje także akt terytorializacji."><sup>34</sup></a>.</p>
                                <p>W jaki sposób uczenie maszynowe kreśli statystyczną mapę świata? Zwróćmy się w stronę specyficznej kwestii, jaką jest rozpoznawanie obrazów (podstawowa forma <strong>pracy percepcji</strong>, która została skodyfikowana i zautomatyzowana jako rozpoznawanie wzorców)<a href="#nooscope-ref-35-bottom" id="nooscope-ref-35-top" class="nooscope-reference-num ai-scroll-to" data-toggle="tooltip" data-html="true" data-original-title="Rozpoznawanie wzorców jest jednym z aspektów ekonomii uwagi. &lt;q&gt;Patrzeć znaczy pracować&lt;/q&gt;, jak przypomina nam Jonathan Beller. Jonathan Beller, &lt;cite&gt;The Cinematic Mode of Production: Attention Economy and the Society of the Spectacle&lt;/cite&gt;. Lebanon, NH: University Press of New England, 2006, 2."><sup>35</sup></a>. Aby sklasyfikować obraz, algorytm wykrywa krawędzie obiektu, które są statystycznym rozkładem ciemnych pikseli otoczonych pikselami jasnymi (typowy wzorzec wizualny). Algorytm nie wie, co jest treścią obrazu, nie postrzega go w taki sam sposób jak człowiek, jedynie liczy piksele, numeryczne wartości jasności i bliskości. Jest tak zaprogramowany, aby rejestrować jedynie ciemne krawędzie profilu (żeby <em>dopasować się</em> do pożądanego wzorca), a nie wszystkie piksele na obrazie (co skutkowałoby <em>nadmiernym dopasowaniem</em> i powtórzeniem całego pola widzenia). Model statystyczny jest prawidłowo wytrenowany, jeżeli w sposób elegancki <strong>dopasuje</strong> tylko istotne wzorce danych treningowych i zastosuje te wzorce to nowych danych „na wolności”. Jeżeli model nauczy się zbioru danych treningowych zbyt dobrze, rozpozna jedynie dokładne przypasowania do oryginalnych wzorców i „na wolności” przeoczy te bardzo do nich podobne. W takim wypadku model jest <strong>nadmiernie dopasowany</strong>, ponieważ nauczył się wszystkiego (łącznie z szumem) i nie jest w stanie odróżnić wzorca od tła. Model jest z kolei <strong>niedopasowany</strong>, kiedy nie jest w stanie wykrywać znaczących wzorców z danych treningowych. Pojęcia nadmiernego dopasowania, dopasowania i niedopasowania danych można zwizualizować na płaszczyźnie kartezjańskiej.</p>
                                <figure class="ai-img-wrap text-center mt-5 mt-sm-5 mt-md-5 mt-lg-5 mt-xl-5">
                                    <img class="img-fluid" src="img/Nooscope_06_Approximation_PL.svg" alt="Aproksymacja">
                                </figure>
                                <p>Wyzwanie związane z nadzorowaniem uczenia maszynowego polega na kalibrowaniu równowagi pomiędzy niedopasowaniem i nadmiernym dopasowaniem danych, co jest trudnym zadaniem ze względu na różne maszynowe błędy systematyczne. Uczenie maszynowe jest pojęciem, które podobnie jak sztuczna inteligencja antropomorfizuje technologię: uczenie maszynowe <em>nie poznaje</em> prawdziwego znaczenia słowa, jak robi to człowiek; uczenie maszynowe po prostu mapuje statystyczną dystrybucję numerycznych wartości i rysuje matematyczną funkcję, która przy odrobinie szczęścia stanowi przybliżenie ludzkiego rozumowania. Z tego właśnie powodu uczenie maszynowe może rzucić nowe światło na sposób, w jaki ludzie rozumują.</p>
                                <p>Model statystyczny algorytmu uczenia maszynowego jest również przybliżeniem w tym sensie, że stara się odgadnąć brakujące fragmenty grafu danych: albo przez <strong>interpolację</strong>, która jest prognozowaniem wyjścia <i>y</i> w znanym interwale wejścia <i>x</i> w zbiorze danych treningowych, albo przez <strong>ekstrapolację</strong>, która jest prognozowaniem wyjścia <i>y</i> poza granicami <i>x</i>, często z większym ryzykiem niedokładności. Tym jest dzisiaj „inteligencja” w inteligencji maszynowej: ekstrapolowaniem funkcji nieliniowej poza granice znanych danych. Jak trafnie ujmuje to Dan McQuillian: „Nie ma inteligencji w sztucznej inteligencji, ani żadnego uczenia się, choć jej techniczną nazwą jest uczenie maszynowe; to jest po prostu matematyczna optymalizacja”<a href="#nooscope-ref-36-bottom" id="nooscope-ref-36-top" class="nooscope-reference-num ai-scroll-to" data-toggle="tooltip" data-html="true" data-original-title="Dan McQuillan, „Manifesto on Algorithmic Humanitarianism.” Zaprezentowane na sympozjum Reimagining Digital Humanitarianism, Goldsmiths, University of London, 16 lutego 2018."><sup>36</sup></a>.</p>
                                <p>Należy jednak przypomnieć, że „inteligencja” uczenia maszynowego nie opiera się na dokładnych formułach analizy matematycznej, ale na algorytmach <strong>aproksymacji metodą siłową</strong>. Kształt funkcji korelacji pomiędzy wejściem <i>x</i> i wyjściem <i>y</i> jest liczony algorytmicznie, krok po kroku, przez uciążliwe mechaniczne procesy stopniowej regulacji (na przykład metodą gradientu prostego), które są odpowiednikiem rachunku różniczkowego Leibniza i Newtona. Sieci neuronowe są uważane za jedne z najbardziej wydajnych algorytmów, ponieważ przy wystarczającej liczbie warstw neuronów i obfitych zasobach obliczeniowych metody różniczkowe mogą <em>przybliżyć</em> kształt dowolnej funkcji<a href="#nooscope-ref-37-bottom" id="nooscope-ref-37-top" class="nooscope-reference-num ai-scroll-to" data-toggle="tooltip" data-html="true" data-original-title="Co zostało udowodnione przez twierdzenie o uniwersalnej aproksymacji."><sup>37</sup></a>. Stopniowe przybliżanie funkcji metodą siłową jest podstawową cechą współczesnej sztucznej inteligencji, i tylko z tej perspektywy można zrozumieć jej potencjał i ograniczenia – szczególnie jej rosnący ślad węglowy (trenowanie głębokich sieci neuronowych wymaga ogromnych zasobów energii, ponieważ metoda gradientu prostego i inne algorytmy trenujące działają na podstawie ciągłego nanoszenia nieskończenie małych korekt)<a href="#nooscope-ref-38-bottom" id="nooscope-ref-38-top" class="nooscope-reference-num ai-scroll-to" data-toggle="tooltip" data-html="true" data-original-title="Ananya Ganesh, Andrew McCallum i Emma Strubell, „Energy and Policy Considerations for Deep Learning in NLP.” ArXiv preprint, 2019. https://arxiv.org/abs/1906.02243"><sup>38</sup></a>.</p>
                            </section>

                            <section>
                                <h2>7. Świat na wektor</h2>
                                <p>Pojęcia dopasowania danych, nadmiernego dopasowania, niedopasowania, interpolacji i ekstrapolacji można łatwo zwizualizować w dwóch wymiarach, jednak modele statystyczne zwykle działają na wielowymiarowych przestrzeniach danych. Dane, zanim zostaną przeanalizowane, zostają zakodowane do <strong>wielowymiarowej przestrzeni wektorów</strong>, która jest mało intuicyjna. Czym jest przestrzeń wektorów i dlaczego jest ona wielowymiarowa? Cardon, Cointet i Mazière opisują wektoryzację danych w ten oto sposób:</p>
                                <blockquote class="quote">Sieć neuronowa wymaga, żeby dane wejściowe przybrały formę wektora. W związku z tym świat musi być najpierw zakodowany w postaci czysto cyfrowej wektorowej reprezentacji. Niektóre obiekty, takie jak obrazy, dają się naturalnie przełożyć na wektory, jednak pozostałe muszą zostać „osadzone” w przestrzeni wektorowej, zanim będzie możliwe ich policzenie lub zaklasyfikowanie w sieciach neuronowych. Tak dzieje się w przypadku tekstu, który jest przykładem prototypowym. Aby wprowadzić słowo do sieci neuronowej, technika <em>Word2vec</em> „osadza” je w przestrzeni wektorowej, która mierzy jego odległość od innych słów w korpusie. W ten sposób słowa otrzymują pozycję w przestrzeni o kilkuset wymiarach. Zaletą takiej reprezentacji jest wielość operacji, które ta transformacja umożliwia. Dwa pojęcia, które według wyliczeń znajdują się blisko siebie w tej przestrzeni, są równie bliskie semantycznie; mówi się wówczas, że te reprezentacje są rozłożone następująco: wektor pojęcia „apartament” [˗0.2, 0.3, ˗4.2, 5.1…] będzie podobny do wektora pojęcia „dom” [˗0.2, 0.3, ˗4.0, 5.1…]. […] Przetwarzanie języka naturalnego było prekursorem w „osadzaniu” słów w przestrzeni wektorowej, a obecnie jesteśmy świadkami generalizacji procesu osadzania, który stopniowo rozszerza się na wszystkie obszary działania: sieci stają się punktami w przestrzeni wektorowej dzięki <em>graph2vec</em>, teksty pisane dzięki <em>paragraph2vec</em>, filmy dzięki <em>movie2vec</em>, znaczenia słów dzięki <em>sens2vec</em>, struktury molekularne dzięki <em>mol2vec</em> itd. Zdaniem Yanna LeCuna celem projektantów maszyn koneksjonistycznych jest przełożenie świata na wektor (<em>world2vec</em>)<a href="#nooscope-ref-39-bottom" id="nooscope-ref-39-top" class="nooscope-reference-num ai-scroll-to" data-toggle="tooltip" data-html="true" data-original-title="Cardon i in., „Neurons Spike Back.”"><sup>39</sup></a>.</blockquote>
                                <p><strong>Wielowymiarowa przestrzeń wektorowa</strong> to jeden z czynników, które utrudniają uchwycenie logiki uczenia maszynowego. To nowa technika kulturowa, z którą warto się zapoznać. W szczególności cyfrowa humanistyka zajmuje się techniką wektoryzacji, dzięki której nasza kolektywna wiedza jest niewidocznie przedstawiana i przetwarzana. William Gibson w swej oryginalnej definicji cyberprzestrzeni najprawdopodobniej przewidział nadejście nie rzeczywistości wirtualnej, lecz przestrzeni wektorowej: <q>Graficzne odwzorowanie danych pobieranych z banków wszystkich komputerów świata. Niewyobrażalna złożoność… Świetlne linie przebiegały bezprzestrzeń umysłu, skupiska i konstelacje danych. Jak światła wielkiego miasta, coraz dalsze…</q><a href="#nooscope-ref-40-bottom" id="nooscope-ref-40-top" class="nooscope-reference-num ai-scroll-to" data-toggle="tooltip" data-html="true" data-original-title="William Gibson &lt;cite&gt;Neuromancer&lt;/cite&gt; w: &lt;cite&gt;Trylogia Ciągu&lt;/cite&gt;, przeł. Piotr W. Cholewa, Wydawnictwo MAG, Warszawa 2015, s. 58."><sup>40</sup></a>.</p>
                                <figure class="ai-img-wrap text-center mt-5 mt-sm-5 mt-md-5 mt-lg-5 mt-xl-5">
                                    <img class="img-fluid" src="img/Nooscope_05_Black_Box_PL.svg" alt="Statua citofonica">
                                    <figcaption class="nooscope-reference-fig-desc small mt-3 mt-sm-3 mt-md-3 mt-lg-3 mt-xl-3">Po prawej: przestrzeń wektorowa siedmiu słów w trzech kontekstach<a href="#nooscope-ref-41-bottom" id="nooscope-ref-41-top" class="nooscope-reference-num ai-scroll-to" data-toggle="tooltip" data-html="true" data-original-title="Źródło: corpling.hypotheses.org/495"><sup>41</sup></a>.</figcaption>
                                </figure>
                                <p>Trzeba jednak zaznaczyć, że uczenie maszynowe wciąż bardziej przypomina rzemiosło niż ścisłą matematykę. SI wciąż jest raczej historią hackowania i trików niż mistycznych intuicji. Dla przykładu, jednym z trików kompresowania informacji jest <strong>redukcja wymiarowości</strong>, którą stosuje się, aby uniknąć „przekleństwa wymiarowości”, czyli wykładniczego wzrostu różnorodności cech w przestrzeni wektorowej. Wymiary kategorii, które wykazują niską zmienność w przestrzeni wektorowej (to znaczy takich, których wartości wahają się nieznacznie), są grupowane, aby zmniejszyć koszty obliczeniowe. Redukcja wymiarowości może zostać wykorzystana w celu klastrowania znaczenia słów (tak jak w przypadku modelu word2vec), ale również prowadzić do <strong>redukcji kategorii</strong>, co może mieć wpływ na reprezentację społecznej różnorodności. Redukcja wymiarowości może zawężać taksonomie i wprowadzać stronniczość, a w efekcie normalizować różnorodność świata i zacierać wyjątkowe tożsamości<a href="#nooscope-ref-42-bottom" id="nooscope-ref-42-top" class="nooscope-reference-num ai-scroll-to" data-toggle="tooltip" data-html="true" data-original-title="Jamie Morgenstern, Samira Samadi, Mohit Singh, Uthaipon Tantipongpipat i Santosh Vempala, „The Price of Fair PCA: One Extra Dimension.” &lt;cite&gt;Advances in Neural Information Processing Systems &lt;/cite&gt;31, 2018."><sup>42</sup></a>.</p>
                                <figure class="ai-img-wrap text-center mt-5 mt-sm-5 mt-md-5 mt-lg-5 mt-xl-5">
                                    <img class="img-fluid" src="img/Nooscope_08_Dimensions_PL.svg" alt="Wymiary">
                                </figure>
                            </section>

                            <section>
                                <h2>8. Społeczeństwo klasyfikujących i przewidujących botów</h2>
                                <p>Większość współczesnych zastosowań uczenia maszynowego może być opisana w nawiązaniu do dwóch modalności klasyfikacji i przewidywania, które nakreślają kontury nowego społeczeństwa kontroli i zarządzania przez statystykę. Klasyfikacja znana jest jako <em>rozpoznawanie wzorców</em>, natomiast przewidywanie można zdefiniować jako <em>wytwarzanie wzorców</em>. Nowy wzorzec jest rozpoznawany albo wytwarzany poprzez przebadanie wewnętrznego rdzenia modelu statystycznego.</p>
                                <p>Maszynową <strong>klasyfikację</strong> zazwyczaj zaprzęga się do pracy, by rozpoznała znak, obiekt albo ludzką twarz oraz przypisała odpowiednią kategorię w oparciu o taksonomię lub konwencję kulturową. Plik wejściowy (na przykład zdjęcie twarzy uchwycone przez kamerę nadzorującą) jest przetwarzany przez model w celu określenia, czy wpisuje się w jego rozkład prawdopodobieństwa, czy nie. Jeżeli tak jest, zostaje on przypisany do odpowiadającej mu etykiety na wyjściu. Od czasów perceptronu klasyfikacja była pierwotnym zastosowaniem sieci neuronowych. Z pojawieniem się uczenia głębokiego technika ta upowszechniła się w klasyfikatorach rozpoznawania twarzy wykorzystywanych zarówno przez policję, jak i producentów smartfonów.</p>
                                <p><strong>Predykcji</strong> w uczeniu maszynowym używa się do prognozowania przyszłych trendów i zachowań na podstawie minionych, czyli do uzupełnienia informacji na podstawie jej fragmentu. W modalności predykcji próbka danych wejściowych (starter) jest używana do przewidywania brakującej części informacji – również na podstawie rozkładu statystycznego modelu (wynikiem mógłby być fragment wykresu numerycznego wybiegającego w przyszłość lub brakująca część obrazu albo pliku dźwiękowego). Nawiasem mówiąc, istnieją inne modalności uczenia maszynowego: rozkład statystyczny modelu może być dynamicznie wizualizowany dzięki technice eksploracji przestrzeni utajonej i – w ostatnich zastosowaniach – <em>eksploracji wzorców</em><a href="#nooscope-ref-43-bottom" id="nooscope-ref-43-top" class="nooscope-reference-num ai-scroll-to" data-toggle="tooltip" data-html="true" data-original-title="O idei wspomaganego i generatywnego tworzenia zob. Roelof Pieters i Samim Winiger, „Creative AI: On the Democratisation and Escalation of Creativity”, 2016. http://www. medium.com/@creativeai/creativeai-9d4b2346faf3"><sup>43</sup></a>.</p>
                                <p>Klasyfikacja i predykcja w uczeniu maszynowym, dziś wszechobecne, ustanawiają nowe formy inwigilacji i zarządzania. Niektóre urządzenia, takie jak autonomiczne pojazdy czy roboty przemysłowe, mogą łączyć obie modalności. Autonomiczny pojazd uczy się rozpoznawać różne obiekty na drodze (ludzi, samochody, przeszkody, znaki) i przewidywać wydarzenia na podstawie decyzji podjętych przez kierowcę-człowieka w podobnych okolicznościach. Nawet jeżeli rozpoznawanie przeszkody na drodze wydaje się gestem neutralnym (a nie jest), identyfikowanie człowieka w oparciu o kategorie płci, rasy i klasy (a w kontekście pandemii COVID-19 – jako zdrowego lub chorego), jak to robią coraz częściej instytucje państwowe, jest gestem nowego reżimu dyscyplinarnego. Pycha zautomatyzowanej klasyfikacji spowodowała odrodzenie się reakcyjnych praktyk lombrozjańskich, o których sądzono, że przeszły już do historii – takich jak automatyczne rozpoznawanie płci (Automatic Gender Recognition – AGR), „poddziedzina rozpoznawania twarzy, której celem jest algorytmiczne identyfikowanie płci osób na podstawie zdjęć lub materiałów wideo”<a href="#nooscope-ref-44-bottom" id="nooscope-ref-44-top" class="nooscope-reference-num ai-scroll-to" data-toggle="tooltip" data-html="true" data-original-title="Os Keyes, „The Misgendering Machines: Trans/HCI Implications of Automatic Gender Recognition.” &lt;cite&gt;Proceedings of the ACM on Human-Computer Interaction&lt;/cite&gt; 2(88), listopad 2018. https://doi.org/10.1145/3274357"><sup>44</sup></a>.</p>
                                <figure class="ai-img-wrap text-center mt-5 mt-sm-5 mt-md-5 mt-lg-5 mt-xl-5">
                                    <img class="img-fluid" src="img/Nooscope_05_Modes_PL.svg" alt="Tryby">
                                </figure>
                                <p>W ostatnim czasie modalność generatywna uczenia maszynowego wywarła wpływ na kulturę: jej wykorzystanie w produkcji materiałów wizualnych zostało odebrane przez środki masowego przekazu jako przekonanie, że sztuczna inteligencja jest „kreatywna” i może w sposób autonomiczny tworzyć sztukę. Dzieło sztuki, które uważa się za wykonane przez SI, zawsze skrywa za sobą pracownika, który zastosował modalność generatywną sieci neuronowej, trenowanej na konkretnym zbiorze danych. Sieć neuronowa działa w tej modalności <em>wstecz</em> (idąc od mniejszej warstwy wyjścia do większej warstwy wejścia), aby wygenerować nowe wzorce po przeszkoleniu w ich klasyfikowaniu, w procesie, który zazwyczaj przebiega od większej warstwy wejścia do mniejszej warstwy wyjścia. Modalność generatywna ma jednak użyteczne zastosowania: może być użyta do weryfikacji tego, czego model się nauczył, to znaczy do pokazania, jak model „widzi świat”. Można ją wykorzystać na przykład w modelu dla samochodu autonomicznego, aby sprawdzić przewidywany scenariusz trasy do przebycia.</p>
                                <p>Popularnym pomysłem na pokazanie tego, jak model statystyczny „widzi świat”, jest Google’owski DeepDream. DeepDream to konwolucyjna sieć neuronowa bazująca na Inception (która jest trenowana na wspomnianym wyżej zbiorze danych ImageNet), zaprogramowana przez Alexandra Mordvintseva w celu wyświetlania halucynacyjnych wzorców. Mordvintsev wpadł na pomysł „odwrócenia sieci do góry nogami” przez zamianę klasyfikatora na generator przy użyciu różnych szumów lub generycznych krajobrazów jako wejścia<a href="#nooscope-ref-45-bottom" id="nooscope-ref-45-top" class="nooscope-reference-num ai-scroll-to" data-toggle="tooltip" data-html="true" data-original-title="Alexander Mordvintsev, Christophe Olah i Mike Tyka, „Inceptionism: Going Deeper into Neural Networks.” Google Research blog, 17 czerwca 2015. https://ai.googleblog.com/2015/06/ inceptionism-going-deeper-into-neural.html"><sup>45</sup></a>. Odkrył w ten sposób, że „sieci neuronowe, które były trenowane, żeby znajdować różnice między obrazami, mają sporo informacji potrzebnych do ich generowania”. W pierwszych eksperymentach DeepDream zewsząd zaczęły wyłaniać się skrzydła ptaka i oczy psa, ponieważ różne rasy psów i gatunki ptaków są ogromnie nadreprezentowane w ImageNet. Okazało się również, że kategoria „hantel” została wyuczona z surrealistycznie przyczepioną do tego przyrządu ludzką ręką. Dowód na to, jak wiele kategorii w ImageNet jest fałszywie przedstawionych.</p>
                                <p>Dwie podstawowe modalności klasyfikacji i generowania mogą być złożone w kolejnych architekturach, takich jak generatywne sieci przeciwstawne (Generative Adversarial Networks). W architekturze GAN sieć neuronowa będąca <em>dyskryminatorem</em> (tradycyjnym klasyfikatorem) powinna rozpoznawać obraz wyprodukowany przez sieć neuronową będącą <em>generatorem</em>, w pętli wzmocnienia, która równocześnie trenuje dwa modele statystyczne. Ze względu na niektóre zbieżne właściwości poszczególnych modeli statystycznych GAN-y bardzo dobrze sprawdziły się w generowaniu wysoce realistycznych obrazów. Z tego powodu były nadużywane do fabrykowania „deep fake’ów”<a href="#nooscope-ref-46-bottom" id="nooscope-ref-46-top" class="nooscope-reference-num ai-scroll-to" data-toggle="tooltip" data-html="true" data-original-title="Deep fake’i są to spreparowane dzieła, takie jak na przykład filmy, w których twarz danej osoby jest podmieniona na twarz kogoś innego, często w celu wytworzenia fake newsów."><sup>46</sup></a>. Jeśli chodzi o reżim prawdy, podobne kontrowersyjne zastosowanie GAN-u ma miejsce w przypadku generowania sztucznych danych w badaniach nad rakiem, w których sieci neuronowe trenowane na źle zrównoważonym zbiorze danych zawierającym tkanki nowotworowe dopatrywały się nowotworu tam, gdzie go nie było<a href="#nooscope-ref-47-bottom" id="nooscope-ref-47-top" class="nooscope-reference-num ai-scroll-to" data-toggle="tooltip" data-html="true" data-original-title="Joseph Paul Cohen, Sina Honari i Margaux Luck, „Distribution Matching Losses Can Hallucinate Features in Medical Image Translation.” International Conference on Medical Image Computing and Computer-Assisted Intervention. Cham: Springer, 2018. arXiv:1805.08841"><sup>47</sup></a>. W tym przypadku „zamiast poznawać rzeczy, zaczęliśmy je wynajdywać”, jak zauważa Fabian Offert, <q>przestrzeń poznania jest identyczna z przestrzenią wiedzy, którą GAN już posiadał. […] Kiedy myślimy, że widzimy przez GAN – patrząc na coś za pomocą GAN-u – właściwie patrzymy <em>w głąb</em> GAN-u. Wizja GAN-u nie jest rozszerzoną rzeczywistością, jest rzeczywistością wirtualną. GAN-y rozmywają poznawanie i wynajdywanie</q><a href="#nooscope-ref-48-bottom" id="nooscope-ref-48-top" class="nooscope-reference-num ai-scroll-to" data-toggle="tooltip" data-html="true" data-original-title="Fabian Offert, Neural Network Cultures panel, Transmediale festival and KIM HfG Karlsruhe. Berlin, 1 lutego 2020. http://kim.hfg-karlsruhe.de/events/neural-network-cultures"><sup>48</sup></a>. GAN-owska symulacja nowotworu mózgu jest tragicznym przykładem opartej na sztucznej inteligencji naukowej halucynacji.</p>
                                <figure class="ai-img-wrap text-center mt-5 mt-sm-5 mt-md-5 mt-lg-5 mt-xl-5">
                                    <img class="img-fluid" src="img/Nooscope-09-Tumor.gif" alt="Tumor">
                                    <figcaption class="nooscope-reference-fig-desc small mt-3 mt-sm-3 mt-md-3 mt-lg-3 mt-xl-3">Joseph Paul Cohen, Margaux Luck and Sina Honari. „Distribution Matching Losses Can Hallucinate Features in Medical Image Translation”, 2018. Dzięki uprzejmości autorów.</figcaption>
                                </figure>
                            </section>

                            <section>
                                <h2>9. Błędy narzędzia statystycznego: niewykrywanie tego, co nowe</h2>
                                <p>Normatywna siła sztucznej inteligencji w XXI wieku powinna być szczegółowo przeanalizowana pod kątem następujących zagadnień epistemicznych: co oznacza przekształcanie zbiorowej wiedzy we wzorce oraz co oznacza kreślenie przestrzeni wektorowych i rozkładów statystycznych zachowań społecznych? Według Foucaulta już w nowożytnej Francji wykorzystywano siłę statystyki do mierzenia norm społecznych i odróżniania zachowań normalnych od anormalnych<a href="#nooscope-ref-49-bottom" id="nooscope-ref-49-top" class="nooscope-reference-num ai-scroll-to" data-toggle="tooltip" data-html="true" data-original-title="Michel Foucault, &lt;cite&gt;Abnormal: Lectures at the Collège de France 1974-1975&lt;/cite&gt;. New York: Picador, 2004, 26."><sup>49</sup></a>. Sztuczna inteligencja z łatwością zwiększa „moc normalizacji” nowoczesnych instytucji, takich jak biurokracja, medycyna czy statystyka (w pierwotnym rozumieniu, jako posiadana przez państwo wiedza na temat jego populacji, wyrażona w formie danych liczbowych), ze względu na to, że przechodzą one w ręce korporacji zajmujących się sztuczną inteligencją właśnie. Normy instytucjonalne stały się normami komputacyjnymi: klasyfikacja podmiotu – ciał i zachowań – nie wydaje się już sprawą rejestrów publicznych, ale algorytmów i centrów danych<a href="#nooscope-ref-50-bottom" id="nooscope-ref-50-top" class="nooscope-reference-num ai-scroll-to" data-toggle="tooltip" data-html="true" data-original-title="Na temat norm komputacyjnych zob. Matteo Pasquinelli, „Arcana Mathematica Imperii: The Evolution of Western Computational Norms.’ w: Maria Hlavajova i in. (eds), &lt;cite&gt;Former West&lt;/cite&gt;. Cambridge, MA: MIT Press, 2017."><sup>50</sup></a>. Jak podsumowuje Paula Duarte: <q>racjonalność oparta na danych powinna być rozumiana jako wyraz kolonialności władzy</q><a href="#nooscope-ref-51-bottom" id="nooscope-ref-51-top" class="nooscope-reference-num ai-scroll-to" data-toggle="tooltip" data-html="true" data-original-title="Paola Ricaurte, „Data Epistemologies, The Coloniality of Power, and Resistance.” &lt;cite&gt;Television &amp;amp; New Media,&lt;/cite&gt; 7 marca 2019."><sup>51</sup></a>.</p>
                                <p>Zawsze jednak istnieje jakaś luka, tarcie bądź konflikt między modelami statystycznymi SI a ludzkim podmiotem, który ma być mierzony i kontrolowany. Ta logiczna luka pomiędzy modelami statystycznymi SI a społeczeństwem jest zazwyczaj omawiana jako <strong>błąd systematyczny (bias)</strong>. Zostało obszernie wykazane, w jaki sposób rozpoznawanie twarzy fałszywie przedstawia mniejszości społeczne i jak na przykład czarne dzielnice są omijane przez usługi logistyczne i dostawcze oparte na sztucznej inteligencji<a href="#nooscope-ref-52-bottom" id="nooscope-ref-52-top" class="nooscope-reference-num ai-scroll-to" data-toggle="tooltip" data-html="true" data-original-title="David Ingold i Spencer Soper, „Amazon Doesn’t Consider the Race of its Customers. Should It?”, Bloomberg, 21 kwietnia 2016. https://www.bloomberg.com/graphics/2016-amazon-same-day"><sup>52</sup></a>. Jeżeli dyskryminacja ze względu na płeć, rasę lub klasę społeczną jest wzmocniona algorytmami SI, jest to również częścią bardziej złożonego problemu dyskryminacji i normalizacji w logicznym rdzeniu uczenia maszynowego. Logicznym i politycznym ograniczeniem sztucznej inteligencji jest trudność, jaką technologii sprawia <strong>rozpoznawanie oraz przewidywanie nowych zdarzeń</strong>. W jaki sposób uczenie maszynowe radzi sobie z faktycznie wyjątkową anomalią, nietypowym zachowaniem społecznym czy innowacyjnym działaniem zakłócającym? Dwie modalności uczenia maszynowego pokazują ograniczenie, które nie jest wyłącznie błędem systematycznym.</p>
                                <p>Logicznym ograniczeniem maszynowej klasyfikacji i rozpoznawania wzorców jest niemożność zidentyfikowania <strong>wyjątkowej anomalii</strong>, która pojawia się po raz pierwszy, takiej jak nowa poetycka metafora, nowy żart w codziennej rozmowie czy niezwykła przeszkoda (pieszy? plastikowa torba?) na drodze. <strong>Nierozpoznanie tego, co nowe</strong> (czegoś, czego model nigdy wcześniej nie „widział”, a zatem nigdy nie przyporządkował do znanej kategorii), jest szczególnie niebezpieczne w przypadku samochodów autonomicznych i stało się już przyczyną zgonów. Przewidywanie maszynowe i generowanie wzorców wykazują podobne błędy w odgadywaniu przyszłych trendów i zachowań. Jako technika kompresji informacji uczenie maszynowe automatyzuje dyktaturę przeszłości, przeszłych taksonomii i wzorców zachowań, nad teraźniejszością. Problem ten można nazwać <strong>odrodzeniem minionego</strong> – zastosowaniem homogenicznego spojrzenia na czasoprzestrzeń, które ogranicza możliwość wystąpienia nowego wydarzenia historycznego.</p>
                                <p>Co ciekawe, w uczeniu maszynowym logiczna definicja problemu bezpieczeństwa opisuje również logiczne ograniczenie jego twórczego potencjału. Problemy charakterystyczne dla <strong>przewidywania tego, co nowe</strong>, są logicznie powiązane z tymi, które charakteryzują <strong>generację tego, co nowe</strong>, ponieważ sposób, w jaki algorytm uczenia maszynowego przewiduje trend na wykresie czasowym, jest identyczny ze sposobem, w jaki generuje nową grafikę z wyuczonych wzorców. Oklepane pytanie: „czy SI może być kreatywna?” powinno zostać przeformułowane pod względem technicznym: czy uczenie maszynowe jest w stanie tworzyć dzieła, które nie są imitacją przeszłości? Czy uczenie maszynowe jest w stanie ekstrapolować poza stylistyczne granice danych treningowych? „Kreatywność” uczenia maszynowego ogranicza się do wykrywania stylów na podstawie danych treningowych, a następnie do przypadkowej improwizacji w obrębie tych stylów. Innymi słowy, uczenie maszynowe może eksplorować i improwizować tylko w granicach logicznych wyznaczonych przez dane treningowe. Ze względu na wszystkie te kwestie, jak również na stopień kompresji informacji, bardziej trafne byłoby określenie sztuki tworzonej przez uczenie maszynowe jako <em>sztuki statystycznej</em>.</p>
                                <figure class="ai-img-wrap text-center mt-5 mt-sm-5 mt-md-5 mt-lg-5 mt-xl-5">
                                    <img class="img-fluid" src="img/Nooscope_10_weather.gif" alt="Statua citofonica">
                                    <figcaption class="nooscope-reference-fig-desc small mt-3 mt-sm-3 mt-md-3 mt-lg-3 mt-xl-3">Lewis Fry Richardson, Weather Prediction by Numerical Process, Cambridge University Press, 1922.</figcaption>
                                </figure>
                                <p>Innym niewypowiedzianym błędem w uczeniu maszynowym jest to, że korelacja statystyczna między dwoma zjawiskami jest często traktowana jako zachodzący między nimi związek przyczynowy. W statystyce powszechnie przyjmuje się, że <strong>korelacja nie oznacza związku przyczynowego</strong>, co oznacza, że sam statystyczny zbieg okoliczności nie jest wystarczający do wykazania związku przyczynowego. Tragiczny przykład takiego błędu można znaleźć w pracy statystyka Fredericka Hoffmana, który w 1896 roku opublikował 330-stronicowy raport dla towarzystw ubezpieczeniowych, aby wykazać <em>rasową korelację</em> między byciem czarnym Amerykaninem a krótką oczekiwaną długością życia<a href="#nooscope-ref-53-bottom" id="nooscope-ref-53-top" class="nooscope-reference-num ai-scroll-to" data-toggle="tooltip" data-html="true" data-original-title="Cathy O’Neil, &lt;cite&gt;Weapons of Math Destruction&lt;/cite&gt;. New York: Broadway Books, 2016, ch 9."><sup>53</sup></a>. Przez powierzchowne eksplorowanie danych uczenie maszynowe może stworzyć dowolną korelację, która będzie postrzegana jako rzeczywista. W 2008 roku ten błąd logiczny z dumą popełnił redaktor naczelny miesięcznika „Wired”, Chris Anderson, który ogłosił „koniec teorii”, ponieważ <q>potop danych sprawia, że metoda naukowa staje się przestarzała</q><a href="#nooscope-ref-54-bottom" id="nooscope-ref-54-top" class="nooscope-reference-num ai-scroll-to" data-toggle="tooltip" data-html="true" data-original-title="Chris Anderson, „The End of Theory: The Data Deluge Makes the Scientific Method Obsolete.” &lt;cite&gt;Wired&lt;/cite&gt;, 23 czerwca 2008. Dla krytycznych uwag zob.: Fulvio Mazzocchi, „Could Big Data Be the End of Theory in Science? A Few Remarks on the Epistemology of Data-Driven Science.” EMBO Reports 16(10), 2015."><sup>54</sup></a>. Według Andersona, który sam nie jest ekspertem od metod naukowych i logicznego wnioskowania, korelacja statystyczna wystarcza do prowadzenia opartego o system reklamowy biznesu Google'a, wobec czego musi być wystarczająco dobra, aby automatycznie odkrywać paradygmaty naukowe. Nawet Judea Pearl, pionier sieci bayesowskich, uważa, że uczenie maszynowe ma obsesję na punkcie „dopasowywania krzywych”, czyli rejestrowania korelacji bez podawania wyjaśnień<a href="#nooscope-ref-55-bottom" id="nooscope-ref-55-top" class="nooscope-reference-num ai-scroll-to" data-toggle="tooltip" data-html="true" data-original-title="Judea Pearl i Dana Mackenzie, &lt;cite&gt;The Book of Why: The New Science of Cause and Effect&lt;/cite&gt;. New York: Basic Books, 2018."><sup>55</sup></a>. Taki błąd logiczny jest już błędem politycznym, jeśli weźmie się pod uwagę, że służby porządkowe na całym świecie przyjęły predykcyjne algorytmy policyjne<a href="#nooscope-ref-56-bottom" id="nooscope-ref-56-top" class="nooscope-reference-num ai-scroll-to" data-toggle="tooltip" data-html="true" data-original-title="Eksperymenty nowojorskiej policji (NYPD) mają miejsce już od późnych lat osiemdziesiątych. Zob. Pasquinelli, „Arcana Mathematica Imperii.”"><sup>56</sup></a>. Według Dana McQuillana kiedy uczenie maszynowe jest stosowane w społeczeństwie w ten sposób, zamienia się w biopolityczny aparat <strong>prewencji</strong>, wytwarzający podmiotowości, które mogą następnie zostać uznane za przestępcze<a href="#nooscope-ref-57-bottom" id="nooscope-ref-57-top" class="nooscope-reference-num ai-scroll-to" data-toggle="tooltip" data-html="true" data-original-title="Dan McQuillan, „People’s Councils for Ethical Machine Learning.” &lt;cite&gt;Social Media and Society&lt;/cite&gt; 4(2), 2018."><sup>57</sup></a>. W ostatecznym rozrachunku uczenie maszynowe ze swoją obsesją na punkcie „dopasowywania krzywych” narzuca <em>kulturę statystyczną</em> i zastępuje tradycyjną episteme przyczynowości (i politycznej odpowiedzialności) korelacją na ślepo napędzaną przez zautomatyzowane podejmowanie decyzji.</p>
                            </section>

                            <section>
                                <h2>10. Inteligencja przeciwstawna vs. sztuczna inteligencja</h2>
                                <p>Do tej pory śledziliśmy statystyczne dyfrakcje i halucynacje uczenia maszynowego krok po kroku przez wiele soczewek nooskopu. W tym momencie kierunek instrumentu musi zostać odwrócony: zarówno teorie naukowe, jak i urządzenia komputacyjne, są skłonne do utrwalania perspektywy abstrakcyjnej – naukowego „punktu widzenia znikąd”, często będącego po prostu punktem widzenia władzy. Obsesyjne zgłębianie sztucznej inteligencji może strącić badacza w otchłań komputacji i iluzji, że forma techniczna oświeca społeczną. Jak zaznacza Paola Ricaurte: <q>ekstraktywizm danych zakłada, że wszystko jest ich źródłem</q><a href="#nooscope-ref-58-bottom" id="nooscope-ref-58-top" class="nooscope-reference-num ai-scroll-to" data-toggle="tooltip" data-html="true" data-original-title="Ricaurte, „Data Epistemologies.”"><sup>58</sup></a>. Jak wyemancypować się z wizji świata, która stawia dane w centrum? Czas uzmysłowić sobie, że to nie model statystyczny tworzy podmiot, lecz podmiot nadaje kształt modelowi statystycznemu. Granica między internalistycznymi i eksternalistycznymi badaniami SI musi się zatrzeć: podmiotowości tworzą matematykę kontroli od wewnątrz, a nie od zewnątrz. O inteligencji maszyn można powiedzieć to, co Guattari stwierdził kiedyś na temat maszyn w ogóle – ona również składa się z <q>hiperrozwiniętych i hiperskoncentrowanych form pewnych aspektów ludzkiej podmiotowości</q><a href="#nooscope-ref-59-bottom" id="nooscope-ref-59-top" class="nooscope-reference-num ai-scroll-to" data-toggle="tooltip" data-html="true" data-original-title="Felix Guattari, &lt;cite&gt;Schizoanalytic Cartographies&lt;/cite&gt;. London: Continuum, 2013, 2."><sup>59</sup></a>.</p>
                                <p>Krytyczne dociekanie bada nie tylko to, jak technologia działa, lecz także to, jak się psuje; jak badani buntują się przeciwko jej normatywnej kontroli, a pracownicy sabotują jej tryby. W tym sensie zwrócenie się w kierunku praktyk hakerskich jest sposobem na zbadanie granic sztucznej inteligencji. Hakowanie to istotna metoda wytwarzania wiedzy, epistemiczna sonda wpuszczona w mrok sztucznej inteligencji<a href="#nooscope-ref-60-bottom" id="nooscope-ref-60-top" class="nooscope-reference-num ai-scroll-to" data-toggle="tooltip" data-html="true" data-original-title="Związek między SI a hakowaniem nie jest tak odległy jak mogłoby się wydawać: często sprowadza się on do pętli wzajemnego uczenia się, oceny i wzmocnienia."><sup>60</sup></a>. Przykładowo, systemy uczenia głębokiego do rozpoznawania twarzy wyzwoliły formy aktywizmu przeciwko inwigilacji. Ludzie postanowili skorzystać z technik kamuflowania twarzy, by pozostać nierozpoznawalnymi dla sztucznej inteligencji, czyli sami stali się <strong>czarnymi skrzynkami</strong>. W dobie uczenia maszynowego tradycyjne techniki <strong>kamuflażu</strong> przeciwko inwigilacji natychmiast nabierają wymiaru matematycznego. Na przykład artysta i badacz sztucznej inteligencji Adam Harvey stworzył HyperFace – kamuflującą tkaninę, która sprawia, że algorytmy widzenia komputerowego dostrzegają wiele ludzkich twarzy tam, gdzie żadnej nie ma<a href="#nooscope-ref-61-bottom" id="nooscope-ref-61-top" class="nooscope-reference-num ai-scroll-to" data-toggle="tooltip" data-html="true" data-original-title="Adam Harvey, HyperFace project, 2016. https://ahprojects.com/hyperface"><sup>61</sup></a>. Dzieło Harveya nasuwa pytanie: czym jest twarz dla ludzkiego oka, a czym dla algorytmu widzenia komputerowego? Kształty na HyperFace wykorzystują tę lukę poznawczą i pokazują, jak ludzka twarz wygląda dla maszyny. Ta luka między percepcją człowieka i maszyny pozwala na realizację coraz liczniejszych ataków przeciwstawnych.</p>
                                <figure class="ai-img-wrap text-center mt-5 mt-sm-5 mt-md-5 mt-lg-5 mt-xl-5">
                                    <img class="img-fluid" src="img/Nooscope-11-Faces.gif" alt="Adam Harvey, HyperFace pattern, 2016.">
                                    <figcaption class="nooscope-reference-fig-desc small mt-3 mt-sm-3 mt-md-3 mt-lg-3 mt-xl-3">Adam Harvey, HyperFace pattern, 2016.</figcaption>
                                </figure>
                                <p><strong>Ataki przeciwstawne</strong> wykorzystują martwe punkty i słabe obszary w modelu statystycznym sieci neuronowej, zwykle po to, aby oszukać klasyfikator i sprawić, by dostrzegł coś, czego nie ma. W rozpoznawaniu obiektów przykładem ataku przeciwstawnego może być wyglądający niewinnie dla ludzkiego oka odpowiednio spreparowany obraz żółwia, błędnie sklasyfikowany przez sieć neuronową jako karabin<a href="#nooscope-ref-62-bottom" id="nooscope-ref-62-top" class="nooscope-reference-num ai-scroll-to" data-toggle="tooltip" data-html="true" data-original-title="Anish Athalye i in., „Synthesizing Robust Adversarial Examples.” ArXiv preprint, 2017. https://arxiv.org/abs/1707.07397"><sup>62</sup></a>. Inne przykłady to obiekty trójwymiarowe, a nawet naklejki na znaki drogowe, które mogą wprowadzić w błąd samochody autonomiczne (jeśli na przykład spowodują odczytanie limitu prędkości 120 km/h, podczas gdy rzeczywisty limit wynosi 50 km/h)<a href="#nooscope-ref-63-bottom" id="nooscope-ref-63-top" class="nooscope-reference-num ai-scroll-to" data-toggle="tooltip" data-html="true" data-original-title="Nir Morgulis i in., „Fooling a Real Car with Adversarial Traffic Signs.” ArXiv preprint, 2019. https://arxiv.org/abs/1907.00374"><sup>63</sup></a>. Przykłady przeciwstawne są projektowane z wykorzystaniem wiedzy o tym, czego maszyna wcześniej nie widziała. Efekt ten można osiągnąć również dzięki zastosowaniu inżynierii odwrotnej na modelu statystycznym lub poprzez zanieczyszczenie trenowanego zbioru danych. W tym ostatnim przypadku wprowadza się spreparowane dane do trenowanego zbioru przy użyciu techniki <strong>zatruwania danych</strong>. Zmienia się w ten sposób dokładność modelu statystycznego i tworzy furtkę, która może być wykorzystana do ataku przeciwstawnego<a href="#nooscope-ref-64-bottom" id="nooscope-ref-64-top" class="nooscope-reference-num ai-scroll-to" data-toggle="tooltip" data-html="true" data-original-title="Zatruwanie danych może być także wykorzystanie w celu ochrony prywatności poprzez wprowadzanie anonimowych lub losowych informacji do zbioru danych."><sup>64</sup></a>.</p>
                                <p>Atak przeciwstawny zdaje się wskazywać na matematyczną lukę, która jest wspólna dla wszystkich modeli uczenia maszynowego: <q>Intrygującym aspektem przykładów przeciwstawnych jest to, że przykład wygenerowany dla jednego modelu jest często błędnie klasyfikowany przez inne modele, nawet jeśli mają one inną architekturę lub zostały przeszkolone na rozłącznych zbiorach treningowych</q><a href="#nooscope-ref-65-bottom" id="nooscope-ref-65-top" class="nooscope-reference-num ai-scroll-to" data-toggle="tooltip" data-html="true" data-original-title="Ian Goodfellow i in., „Explaining and Harnessing Adversarial Examples.” ArXiv preprint, 2014. https://arxiv.org/abs/1412.6572"><sup>65</sup></a>. Ataki przeciwstawne przypominają nam o rozbieżności między percepcją ludzi i maszyn oraz o tym, że logiczne ograniczenie uczenia maszynowego ma również wymiar polityczny. Logiczną i ontologiczną granicą uczenia maszynowego są nieposłuszny podmiot lub anomalne zdarzenie, niedające się sklasyfikować ani poddać kontroli. Podmiot algorytmicznej kontroli kontratakuje. Ataki przeciwstawne to sposób sabotażu linii produkcyjnej uczenia maszynowego poprzez odkrywanie wirtualnych przeszkód, które mogą rozregulować system kontroli. Przykład przeciwstawny jest <em>sabotem</em> w erze sztucznej inteligencji.</p>
                            </section>

                            <section>
                                <h2>11. Praca w czasach SI</h2>
                                <p>Należy wyjaśnić naturę „danych wejściowych” i „danych wyjściowych” uczenia maszynowego. Sztuczna inteligencja ma kłopoty nie tylko ze stronniczością informacji, lecz także z pracą. SI nie jest jedynie aparatem kontroli, ale również aparatem produkcji. Jak już zauważyliśmy, niewidoczna siła robocza jest zaangażowana na każdym odcinku linii montażowej (kompozycja zbioru danych, nadzór algorytmu, ocena modelu itp.). Potok niekończących się zadań przepływa z globalnej Północy na globalne Południe; platformy crowdsourcingowe z pracownikami z Wenezueli, Brazylii czy Włoch mają kluczowe znaczenie przy uczeniu „widzenia” niemieckich samochodów autonomicznych<a href="#nooscope-ref-66-bottom" id="nooscope-ref-66-top" class="nooscope-reference-num ai-scroll-to" data-toggle="tooltip" data-html="true" data-original-title="Florian Schmidt, „Crowdsourced Production of AI Training Data: How Human Workers Teach Self-Driving Cars to See.” Düsseldorf: Hans-Böckler-Stiftung, 2019."><sup>66</sup></a>. Należy podkreślić, że wbrew przekonaniu o pracy pozaludzkiej inteligencji w całym procesie komputacyjnym SI ludzki pracownik nigdy nie wyszedł z obiegu, a dokładniej mówiąc, nigdy nie opuścił linii montażowej. Mary Gray i Siddharth Suri ukuli termin „<strong>praca widmo</strong>” na określenie niewidzialnej pracy, która sprawia, że sztuczna inteligencja wydaje się sztucznie autonomiczna.</p>
                                <blockquote class="quote">Za wyjątkiem zdolności do podjęcia kilku prostych decyzji dzisiejsza SI nie jest w stanie funkcjonować bez ingerencji człowieka. Czy chodzi o dostarczenie odpowiedniego przeglądu informacji, czy też o realizację skomplikowanego zamówienia pizzy poprzez usługę tekstową, kiedy sztuczna inteligencja napotyka na przeszkodę lub nie jest w stanie dokończyć zadania, tysiące firm wzywają ludzi do cichego ukończenia projektu. Ta nowa cyfrowa linia montażowa gromadzi wspólny wkład rozproszonych pracowników, dostarcza raczej części składowe niż całe produkty i działa w wielu sektorach gospodarki o każdej porze dnia i nocy.</blockquote>
                                <p>Automatyzacja to mit; ponieważ maszyny, w tym sztuczna inteligencja, nieustannie potrzebują pomocy ze strony ludzi, niektórzy autorzy sugerują zastąpienie pojęcia „automatyzacja” bardziej adekwatnym pojęciem <strong>heteromatyzacja</strong><a href="#nooscope-ref-67-bottom" id="nooscope-ref-67-top" class="nooscope-reference-num ai-scroll-to" data-toggle="tooltip" data-html="true" data-original-title="Hamid Ekbia i Bonnie Nardi, &lt;cite&gt;Heteromation, and Other Stories of Computing and Capitalism&lt;/cite&gt;. Cambridge, MA: MIT Press, 2017."><sup>67</sup></a>. Heteromatyzacja oznacza, że znana opowieść o SI jako <i>perpetuum mobile</i> jest możliwa tylko dzięki rezerwowej armii robotników.</p>
                                <p>Istnieje jednak głębszy sposób, w jaki praca formuje sztuczną inteligencję. Źródło informacji uczenia maszynowego (niezależnie od tego, czy nazwiemy je: „dane wejściowe”, „dane treningowe” czy po prostu „dane”) zawsze jest reprezentacją ludzkich umiejętności, działań i zachowań – produkcji społecznej w ogóle. Wszystkie zestawy danych treningowych są pośrednio diagramem podziału pracy ludzkiej, który sztuczna inteligencja musi przeanalizować i zautomatyzować. Na przykład zbiory danych do rozpoznawania obrazów to zapis pracy wzrokowej, jaką wykonują kierowcy, strażnicy i nadzorcy w ramach swoich zadań. Nawet naukowe zbiory danych opierają się na pracy naukowej, planowaniu eksperymentów, organizacji laboratorium i obserwacji analitycznej. Przepływ informacji w SI należy rozumieć jako aparat zaprojektowany do ekstrahowania „inteligencji analitycznej” z najróżniejszych form pracy i przenoszenia takiej inteligencji do maszyny (oczywiście obejmując, w ramach definicji pracy, rozszerzone formy produkcji społecznej, kulturowej i naukowej)<a href="#nooscope-ref-68-bottom" id="nooscope-ref-68-top" class="nooscope-reference-num ai-scroll-to" data-toggle="tooltip" data-html="true" data-original-title="O idei inteligencji analitycznej zob. Lorraine Daston, „Calculation and the Division of Labour 1750–1950.” &lt;cite&gt;Bulletin of the German Historical Institute&lt;/cite&gt; 62, 2018."><sup>68</sup></a>. W skrócie, źródłem inteligencji maszynowej jest <strong>podział pracy</strong>, a jej głównym celem jest <strong>automatyzacja pracy</strong>.</p>
                                <p>Badacze historii komputacji zauważali wczesne etapy inteligencji maszynowej już w XIX-wiecznym projekcie mechanizacji podziału pracy umysłowej, a konkretnie w zadaniach polegających na ręcznych obliczeniach<a href="#nooscope-ref-69-bottom" id="nooscope-ref-69-top" class="nooscope-reference-num ai-scroll-to" data-toggle="tooltip" data-html="true" data-original-title="Simon Schaffer, „Babbage’s Intelligence: Calculating Engines and the Factory System”, Critical Inquiry 21, 1994. Lorraine Daston, „Enlightenment calculations”. Critical Inquiry 21, 1994. Matthew L. Jones, &lt;cite&gt;Reckoning with Matter: Calculating Machines, Innovation, and Thinking about Thinking from Pascal to Babbage.&lt;/cite&gt; Chicago: University of Chicago Press, 2016. 62, 2018."><sup>69</sup></a>. Przemysł komputacyjny był od tego czasu połączeniem nadzoru i dyscyplinowania pracy, optymalnego obliczania wartości dodatkowej i planowania zachowań zbiorowych<a href="#nooscope-ref-70-bottom" id="nooscope-ref-70-top" class="nooscope-reference-num ai-scroll-to" data-toggle="tooltip" data-html="true" data-original-title="Matteo Pasquinelli, „On the Origins of Marx’s General Intellect.”&lt;cite&gt; Radical Philosophy&lt;/cite&gt; 2.06, 2019."><sup>70</sup></a>. Komputacja została ustanowiona nie jedynie przez logiczne rozumowanie, lecz przez reżim widoczności i zrozumiałości – który sama wzmacnia. Genealogię sztucznej inteligencji jako aparatu władzy potwierdza dziś jej powszechne zastosowanie w technologiach identyfikacji i przewidywania, jednak podstawową anomalią, która zawsze pozostaje do obliczenia, jest <em>dezorganizacja pracy</em>.</p>
                                <p>Sztuczna inteligencja jako technologia automatyzacji będzie miała ogromny wpływ na rynek pracy. Jeśli na przykład współczynnik błędu w rozpoznawaniu obrazów przy zastosowaniu uczenia głębokiego wynosi 1%, oznacza to, że wykonawców około 99% rutynowych prac opartych na zadaniach wzrokowych (na przykład ochrona lotniskowa) można zastąpić (przy założeniu, że nie przeszkodzą w tym prawne restrykcje ani związki zawodowe). Wpływ sztucznej inteligencji na pracę został dobrze opisany (wreszcie również z perspektywy pracowników) w artykule Europejskiego Instytutu Związków Zawodowych, w którym wyróżniono <q>siedem podstawowych wymiarów, które powinny zostać uwzględnione w przyszłych przepisach w celu ochrony pracowników: 1) zapewnienie ochrony prywatności pracowników oraz ochrony danych; 2) przyjrzenie się problemowi nadzoru, śledzenia i monitorowania; 3) uczynienie transparentnym celu algorytmów SI; 4) zapewnienie wykonalności „prawa do wyjaśnienia” decyzji podejmowanych przez algorytmy lub modele uczenia maszynowego; 5) zapewnienie bezpieczeństwa i ochrony pracownikom w kontaktach człowiek–maszyna; 6) zwiększanie autonomii pracowników w interakcji człowiek–maszyna; 7) umożliwienie pracownikom zdobycia umiejętności potrzebnych do pracy ze sztuczną inteligencją</q><a href="#nooscope-ref-71-bottom" id="nooscope-ref-71-top" class="nooscope-reference-num ai-scroll-to" data-toggle="tooltip" data-html="true" data-original-title="Aida Ponce, „Labour in the Age of AI: Why Regulation is Needed to Protect Workers.” ETUI Research Paper - Foresight Brief 8, 2020. http://dx.doi.org/10.2139/ssrn.3541002"><sup>71</sup></a>.</p>
                                <p>Ostatecznie nooskop opowiada się za zadaniem nowego „Pytania o maszynę” w erze SI. „Pytanie o maszynę” było debatą, która wybuchła w Anglii podczas rewolucji przemysłowej. Wówczas odpowiedzią na wdrożenie maszyn i późniejsze bezrobocie technologiczne robotników była kampania społeczna na rzecz większej edukacji na temat maszyn. Kampania przybrała formę ruchu, który dał początek instytutom mechaniki<a href="#nooscope-ref-72-bottom" id="nooscope-ref-72-top" class="nooscope-reference-num ai-scroll-to" data-toggle="tooltip" data-html="true" data-original-title='Maxine Berg, &lt;cite&gt;The Machinery Question and the Making of Political Economy&lt;/cite&gt;. Cambridge, UK: Cambridge University Press, 1980. W rzeczywistości The Economist przestrzegał niedawno przed "powrotem pytania o maszynę" w erze sztucznej inteligencji. Zob. Tom Standage, „The Return of the Machinery Question.” &lt;cite&gt;The Economist&lt;/cite&gt;, 23 czerwca 2016.'><sup>72</sup></a>. Dziś potrzebne jest „pytanie o inteligentną maszynę”, aby rozwinąć więcej kolektywnej inteligencji na temat „inteligencji maszynowej”, więcej publicznej edukacji zamiast „uczących się maszyn” wraz z ich reżimem ekstraktywizmu wiedzy (który wzmacnia stare, kolonialne szlaki, o czym można się przekonać, jeśli przyjrzymy się mapie zależności na platformach crowdsourcingowych). Ponadto na globalnej Północy należy wysunąć na pierwszy plan tę kolonialną relację między korporacyjną sztuczną inteligencją a wytwarzaniem wiedzy jako dobra wspólnego. Celem nooskopu jest odsłonięcie ukrytego miejsca korporacyjnego „Mechanicznego Turka” i naświetlenie roli niewidzialnej pracy, która sprawia, że inteligencja maszyny wydaje się ideologicznie żywa.</p>
                                <figure class="ai-img-wrap text-center mt-5 mt-sm-5 mt-md-5 mt-lg-5 mt-xl-5">
                                    <img class="img-fluid" src="img/MTurk-02.svg" alt="Mechaniczny Turek">
                                </figure>
                                <p class="text-right">
                                    <em>(przeł. Kuba Kulesza, Cezary Stępkowski, Agnieszka Zgud)</em>
                                </p>
                            </section>

                            <section>
                                <h2>Przypisy</h2>
                                <ul class="nooscope-reference-list list-unstyled">
                                    <li class="nooscope-reference-list-item">
                                        <div class="nooscope-reference d-flex flex-row">
                                            <label id="nooscope-ref-01-bottom" class="nooscope-reference-num small mr-3 mr-sm-3 mr-md-3 mr-lg-3 mr-xl-3">
                                                <a href="#nooscope-ref-01-top" class="ai-scroll-to">1</a>
                                            </label>
                                            <p class="nooscope-reference-desc small">Na temat autonomii technologii zob. Langdon Winner, <cite>Autonomous Technology: Technics-Out-of-Control as a Theme in Political Thought</cite>. Cambridge, MA: MIT Press, 2001.</p>
                                        </div>
                                    </li>

                                    <li class="nooscope-reference-list-item">
                                        <div class="nooscope-reference d-flex flex-row">
                                            <label id="nooscope-ref-02-bottom" class="nooscope-reference-num small mr-3 mr-sm-3 mr-md-3 mr-lg-3 mr-xl-3">
                                                <a href="#nooscope-ref-02-top" class="ai-scroll-to">2</a>
                                            </label>
                                            <p class="nooscope-reference-desc small">O rozszerzeniu władzy kolonialnej na operacje logistyczne, algorytmy i finanse zob. Sandro Mezzadra and Brett Neilson, <cite>The Politics of Operations: Excavating Contemporary Capitalism</cite>. Durham: Duke University Press, 2019. Na temat epistemicznego kolonializmu AI - zob. Matteo Pasquinelli, „Three Thousand Years of Algorithmic Rituals.” <cite>e-flux</cite> 101, 2019.</p>
                                        </div>
                                    </li>

                                    <li class="nooscope-reference-list-item">
                                        <div class="nooscope-reference d-flex flex-row">
                                            <label id="nooscope-ref-03-bottom" class="nooscope-reference-num small mr-3 mr-sm-3 mr-md-3 mr-lg-3 mr-xl-3">
                                                <a href="#nooscope-ref-03-top" class="ai-scroll-to">3</a>
                                            </label>
                                            <p class="nooscope-reference-desc small">W humanistyce cyfrowej funkcjonuje pojęcie <em>czytania zapośredniczonego</em>, dzięki któremu powoli zaczęto angażować analizę danych i uczenie maszynowe w historię literatury i sztuki. Zob. Franco Moretti, <cite>Distant Reading</cite>. London: Verso, 2013.</p>
                                        </div>
                                    </li>

                                    <li class="nooscope-reference-list-item">
                                        <div class="nooscope-reference d-flex flex-row">
                                            <label id="nooscope-ref-04-bottom" class="nooscope-reference-num small mr-3 mr-sm-3 mr-md-3 mr-lg-3 mr-xl-3">
                                                <a href="#nooscope-ref-04-top" class="ai-scroll-to">4</a>
                                            </label>
                                            <p class="nooscope-reference-desc small">Gottfried W. Leibniz, „Przedmowa do nauki ogólnej”, 1677. W: tenże <cite>Wyznanie wiary filozofa...</cite>, przeł. S. Cichowicz i in. Warszawa, 1969, 74.</p>
                                        </div>
                                    </li>

                                    <li class="nooscope-reference-list-item">
                                        <div class="nooscope-reference d-flex flex-row">
                                            <label id="nooscope-ref-05-bottom" class="nooscope-reference-num small mr-3 mr-sm-3 mr-md-3 mr-lg-3 mr-xl-3">
                                                <a href="#nooscope-ref-05-top" class="ai-scroll-to">5</a>
                                            </label>
                                            <p class="nooscope-reference-desc small">Aby uzyskać więcej informacji na temat zwięzłej historii SI zob. Dominique Cardon, Jean-Philippe Cointet and Antoine Mazières, „Neurons Spike Back: The Invention of Inductive Machines and the Artificial Intelligence Controversy.” <cite>Réseaux</cite> 211, 2018.</p>
                                        </div>
                                    </li>

                                    <li class="nooscope-reference-list-item">
                                        <div class="nooscope-reference d-flex flex-row">
                                            <label id="nooscope-ref-06-bottom" class="nooscope-reference-num small mr-3 mr-sm-3 mr-md-3 mr-lg-3 mr-xl-3">
                                                <a href="#nooscope-ref-06-top" class="ai-scroll-to">6</a>
                                            </label>
                                            <p class="nooscope-reference-desc small">Alexander Campolo i Kate Crawford, „Enchanted Determinism: Power without Control in Artificial Intelligence.” <cite>Engaging Science, Technology, and Society</cite> 6, 2020.</p>
                                        </div>
                                    </li>

                                    <li class="nooscope-reference-list-item">
                                        <div class="nooscope-reference d-flex flex-row">
                                            <label id="nooscope-ref-07-bottom" class="nooscope-reference-num small mr-3 mr-sm-3 mr-md-3 mr-lg-3 mr-xl-3">
                                                <a href="#nooscope-ref-07-top" class="ai-scroll-to">7</a>
                                            </label>
                                            <p class="nooscope-reference-desc small">Zastosowanie analogii wizualnej ma na celu również to, by uchwycić zanikające rozróżnienie pomiędzy obrazem a logiką, reprezentacją i wnioskowaniem, w technicznej konstrukcji SI. Modele statystyczne uczenia maszynowego są reprezentacjami operacyjnymi (w rozumieniu takim jak obrazy operacyjne u Haruna Farockiego).</p>
                                        </div>
                                    </li>

                                    <li class="nooscope-reference-list-item">
                                        <div class="nooscope-reference d-flex flex-row">
                                            <label id="nooscope-ref-08-bottom" class="nooscope-reference-num small mr-3 mr-sm-3 mr-md-3 mr-lg-3 mr-xl-3">
                                                <a href="#nooscope-ref-08-top" class="ai-scroll-to">8</a>
                                            </label>
                                            <p class="nooscope-reference-desc small">O systematycznym studium logicznych ograniczeń uczenia maszynowego zob. Momin Mailk, „A Hierarchy of Limitations in Machine Learning.’ Arxiv preprint, 2020. https://arxiv.org/abs/2002.05193</p>
                                        </div>
                                    </li>

                                    <li class="nooscope-reference-list-item">
                                        <div class="nooscope-reference d-flex flex-row">
                                            <label id="nooscope-ref-09-bottom" class="nooscope-reference-num small mr-3 mr-sm-3 mr-md-3 mr-lg-3 mr-xl-3">
                                                <a href="#nooscope-ref-09-top" class="ai-scroll-to">9</a>
                                            </label>
                                            <p class="nooscope-reference-desc small">Na temat bardziej szczegółowej listy błędów SI zob. John Guttag and Harini Suresh, „A Framework for Understanding Unintended Consequences of Machine Learning.” Arxiv preprint, 2019. https://arxiv.org/abs/1901.10002 Zob. także: Aram Galstyan, Kristin Lerman, Ninareh Mehrabi, Fred Morstatter i Nripsuta Saxena, „A Survey on Bias and Fairness in Machine Learning.” Arxiv preprint, 2019. https://arxiv.org/abs/1908.09635 </p>
                                        </div>
                                    </li>

                                    <li class="nooscope-reference-list-item">
                                        <div class="nooscope-reference d-flex flex-row">
                                            <label id="nooscope-ref-10-bottom" class="nooscope-reference-num small mr-3 mr-sm-3 mr-md-3 mr-lg-3 mr-xl-3">
                                                <a href="#nooscope-ref-10-top" class="ai-scroll-to">10</a>
                                            </label>
                                            <p class="nooscope-reference-desc small">Virginia Eubanks, <cite>Automating Inequality</cite>. New York: St. Martin’s Press, 2018. Zob. także: Kate Crawford, „The Trouble with Bias.” Keynote lecture, Conference on Neural Information Processing Systems, 2017.</p>
                                        </div>
                                    </li>

                                    <li class="nooscope-reference-list-item">
                                        <div class="nooscope-reference d-flex flex-row">
                                            <label id="nooscope-ref-11-bottom" class="nooscope-reference-num small mr-3 mr-sm-3 mr-md-3 mr-lg-3 mr-xl-3">
                                                <a href="#nooscope-ref-11-top" class="ai-scroll-to">11</a>
                                            </label>
                                            <p class="nooscope-reference-desc small">Ruha Benjamin, <cite>Race After Technology: Abolitionist Tools for the New Jim Code</cite>. Cambridge, UK: Polity, 2019, 5.</p>
                                        </div>
                                    </li>

                                    <li class="nooscope-reference-list-item">
                                        <div class="nooscope-reference d-flex flex-row">
                                            <label id="nooscope-ref-12-bottom" class="nooscope-reference-num small mr-3 mr-sm-3 mr-md-3 mr-lg-3 mr-xl-3">
                                                <a href="#nooscope-ref-12-top" class="ai-scroll-to">12</a>
                                            </label>
                                            <p class="nooscope-reference-desc small">Informatycy przekonują, że SI jest zagadnieniem z dziedziny <em>przetwarzania sygnałów</em>, a konkretnie z poddziedziny <em>kompresji danych</em>.</p>
                                        </div>
                                    </li>

                                    <li class="nooscope-reference-list-item">
                                        <div class="nooscope-reference d-flex flex-row">
                                            <label id="nooscope-ref-13-bottom" class="nooscope-reference-num small mr-3 mr-sm-3 mr-md-3 mr-lg-3 mr-xl-3">
                                                <a href="#nooscope-ref-13-top" class="ai-scroll-to">13</a>
                                            </label>
                                            <p class="nooscope-reference-desc small">Matteo Pasquinelli, <cite>The Eye of the Master</cite>. London: Verso, w przygotowaniu.</p>
                                        </div>
                                    </li>

                                    <li class="nooscope-reference-list-item">
                                        <div class="nooscope-reference d-flex flex-row">
                                            <label id="nooscope-ref-14-bottom" class="nooscope-reference-num small mr-3 mr-sm-3 mr-md-3 mr-lg-3 mr-xl-3">
                                                <a href="#nooscope-ref-14-top" class="ai-scroll-to">14</a>
                                            </label>
                                            <p class="nooscope-reference-desc small">Projekty takie jak między innymi wytłumaczalna sztuczna inteligencja czy interpretowalne uczenie głębokie i mapy cieplne udowodniły, że przebicie się do "czarnej skrzynki" uczenia maszynowego jest możliwe. Niemniej jednak pełna interpretowalność i wytłumaczalność modeli statystycznych uczenia maszynowego pozostaje mitem. Zob. Zacharay Lipton, „The Mythos of Model Interpretability.” ArXiv preprint, 2016. https://arxiv.org/abs/1606.03490</p>
                                        </div>
                                    </li>

                                    <li class="nooscope-reference-list-item">
                                        <div class="nooscope-reference d-flex flex-row">
                                            <label id="nooscope-ref-15-bottom" class="nooscope-reference-num small mr-3 mr-sm-3 mr-md-3 mr-lg-3 mr-xl-3">
                                                <a href="#nooscope-ref-15-top" class="ai-scroll-to">15</a>
                                            </label>
                                            <p class="nooscope-reference-desc small">A. Corsani, B. Paulré, C. Vercellone, J.M. Monnier, M. Lazzarato, P. Dieuaide and Y. Moulier-Boutang, „Le Capitalisme cognitif comme sortie de la crise du capitalisme industriel. Un programme de recherché”, Paris: Laboratoire Isys Matisse, Maison des Sciences Economiques, 2004. See also: Zuboff, Shoshana, <cite>The Age of Surveillance Capitalism: The Fight for a Human Future at the New Frontier of Power</cite>. London: Profile Books, 2019.</p>
                                        </div>
                                    </li>

                                    <li class="nooscope-reference-list-item">
                                        <div class="nooscope-reference d-flex flex-row">
                                            <label id="nooscope-ref-16-bottom" class="nooscope-reference-num small mr-3 mr-sm-3 mr-md-3 mr-lg-3 mr-xl-3">
                                                <a href="#nooscope-ref-16-top" class="ai-scroll-to">16</a>
                                            </label>
                                            <p class="nooscope-reference-desc small">Lisa Gitelman (ed.), <cite>Raw Data is an Oxymoron</cite>, Cambridge, MA: MIT Press, 2013.</p>
                                        </div>
                                    </li>

                                    <li class="nooscope-reference-list-item">
                                        <div class="nooscope-reference d-flex flex-row">
                                            <label id="nooscope-ref-17-bottom" class="nooscope-reference-num small mr-3 mr-sm-3 mr-md-3 mr-lg-3 mr-xl-3">
                                                <a href="#nooscope-ref-17-top" class="ai-scroll-to">17</a>
                                            </label>
                                            <p class="nooscope-reference-desc small">In supervised learning. Also self-supervised learning maintains forms of human intervention.</p>
                                        </div>
                                    </li>

                                    <li class="nooscope-reference-list-item">
                                        <div class="nooscope-reference d-flex flex-row">
                                            <label id="nooscope-ref-18-bottom" class="nooscope-reference-num small mr-3 mr-sm-3 mr-md-3 mr-lg-3 mr-xl-3">
                                                <a href="#nooscope-ref-18-top" class="ai-scroll-to">18</a>
                                            </label>
                                            <p class="nooscope-reference-desc small">Na temat taksonomii jako formy wiedzy i siły zob. Michel Foucault, <cite>The Order of Things</cite>. London: Routledge, 2005.</p>
                                        </div>
                                    </li>

                                    <li class="nooscope-reference-list-item">
                                        <div class="nooscope-reference d-flex flex-row">
                                            <label id="nooscope-ref-19-bottom" class="nooscope-reference-num small mr-3 mr-sm-3 mr-md-3 mr-lg-3 mr-xl-3">
                                                <a href="#nooscope-ref-19-top" class="ai-scroll-to">19</a>
                                            </label>
                                            <p class="nooscope-reference-desc small">Na przykład stworzony przez Amazon Mechaniczny Turek, cynicznie nazwany przez Jeffa Bezosa "sztuczną sztuczną inteligencją". Zob. Jason Pontin, „Artificial Intelligence, With Help from the Humans.” <cite>The New York Times,</cite> 25 marca 2007.</p>
                                        </div>
                                    </li>

                                    <li class="nooscope-reference-list-item">
                                        <div class="nooscope-reference d-flex flex-row">
                                            <label id="nooscope-ref-20-bottom" class="nooscope-reference-num small mr-3 mr-sm-3 mr-md-3 mr-lg-3 mr-xl-3">
                                                <a href="#nooscope-ref-20-top" class="ai-scroll-to">20</a>
                                            </label>
                                            <p class="nooscope-reference-desc small">Chociaż architektura konwolucyjna sięga czasów prac Yanna LeCunna pod koniec lat osiemdziesiątych, uczenie głębokie zaczęło się od tego artykułu: Geoffrey Hinton, Alex Krizhevsky i Ilya Sutskever, „ImageNet Classification with Deep Convolutional Neural Networks.” <cite>Communications of the ACM</cite> 60(6), 2017.</p>
                                        </div>
                                    </li>

                                    <li class="nooscope-reference-list-item">
                                        <div class="nooscope-reference d-flex flex-row">
                                            <label id="nooscope-ref-21-bottom" class="nooscope-reference-num small mr-3 mr-sm-3 mr-md-3 mr-lg-3 mr-xl-3">
                                                <a href="#nooscope-ref-21-top" class="ai-scroll-to">21</a>
                                            </label>
                                            <p class="nooscope-reference-desc small">Dla przystępnych (ale niezbyt krytycznych) uwag na temat rozwoju ImageNetu zob. Melanie Mitchell, <cite>Artificial Intelligence: A Guide for Thinking Humans</cite>. London: Penguin, 2019.</p>
                                        </div>
                                    </li>

                                    <li class="nooscope-reference-list-item">
                                        <div class="nooscope-reference d-flex flex-row">
                                            <label id="nooscope-ref-22-bottom" class="nooscope-reference-num small mr-3 mr-sm-3 mr-md-3 mr-lg-3 mr-xl-3">
                                                <a href="#nooscope-ref-22-top" class="ai-scroll-to">22</a>
                                            </label>
                                            <p class="nooscope-reference-desc small">WordNet jest <q>leksykalną bazdą danych relacji semantycznych między słowami</q>, która została zapoczątkowana przez George'a Armitage'a na Uniwersytecie Princeton w 1985 roku. Zapewnia ona ścisłą drzewiastą strukturę definicji.</p>
                                        </div>
                                    </li>

                                    <li class="nooscope-reference-list-item">
                                        <div class="nooscope-reference d-flex flex-row">
                                            <label id="nooscope-ref-23-bottom" class="nooscope-reference-num small mr-3 mr-sm-3 mr-md-3 mr-lg-3 mr-xl-3">
                                                <a href="#nooscope-ref-23-top" class="ai-scroll-to">23</a>
                                            </label>
                                            <p class="nooscope-reference-desc small">Kate Crawford i Trevor Paglen, „Excavating AI: The Politics of Training Sets for Machine Learning.” 19 września 2019. https://excavating.ai</p>
                                        </div>
                                    </li>

                                    <li class="nooscope-reference-list-item">
                                        <div class="nooscope-reference d-flex flex-row">
                                            <label id="nooscope-ref-24-bottom" class="nooscope-reference-num small mr-3 mr-sm-3 mr-md-3 mr-lg-3 mr-xl-3">
                                                <a href="#nooscope-ref-24-top" class="ai-scroll-to">24</a>
                                            </label>
                                            <p class="nooscope-reference-desc small">Adam Harvey i Jules LaPlace, Megapixel project, 2019. https://megapixels.cc/about/ i: Madhumita Murgia, „Who's Using Your Face? The Ugly Truth About Facial Recognition.” <cite>Financial Times</cite>, 19 kwietnia 2019.</p>
                                        </div>
                                    </li>

                                    <li class="nooscope-reference-list-item">
                                        <div class="nooscope-reference d-flex flex-row">
                                            <label id="nooscope-ref-25-bottom" class="nooscope-reference-num small mr-3 mr-sm-3 mr-md-3 mr-lg-3 mr-xl-3">
                                                <a href="#nooscope-ref-25-top" class="ai-scroll-to">25</a>
                                            </label>
                                            <p class="nooscope-reference-desc small">Ogólne rozporządzenie o ochronie danych, które zostało przyjęte przez Parlament Europejski w maju 2018 jest mimo wszystko krokiem naprzód w porównaniu do wciąż trwającego braku regulacji w Stanach Zjednoczonych.</p>
                                        </div>
                                    </li>

                                    <li class="nooscope-reference-list-item">
                                        <div class="nooscope-reference d-flex flex-row">
                                            <label id="nooscope-ref-26-bottom" class="nooscope-reference-num small mr-3 mr-sm-3 mr-md-3 mr-lg-3 mr-xl-3">
                                                <a href="#nooscope-ref-26-top" class="ai-scroll-to">26</a>
                                            </label>
                                            <p class="nooscope-reference-desc small">Frank Rosenblatt, „The Perceptron: A Perceiving and Recognizing Automaton.” Cornell Aeronautical Laboratory Report 85-460-1, 1957.</p>
                                        </div>
                                    </li>

                                    <li class="nooscope-reference-list-item">
                                        <div class="nooscope-reference d-flex flex-row">
                                            <label id="nooscope-ref-27-bottom" class="nooscope-reference-num small mr-3 mr-sm-3 mr-md-3 mr-lg-3 mr-xl-3">
                                                <a href="#nooscope-ref-27-top" class="ai-scroll-to">27</a>
                                            </label>
                                            <p class="nooscope-reference-desc small">Warren McCulloch i Walter Pitts, „How We Know Universals: The Perception of Auditory and Visual Forms.” <cite>The Bulletin of Mathematical Biophysics</cite> 9(3): 1947.</p>
                                        </div>
                                    </li>

                                    <li class="nooscope-reference-list-item">
                                        <div class="nooscope-reference d-flex flex-row">
                                            <label id="nooscope-ref-28-bottom" class="nooscope-reference-num small mr-3 mr-sm-3 mr-md-3 mr-lg-3 mr-xl-3">
                                                <a href="#nooscope-ref-28-top" class="ai-scroll-to">28</a>
                                            </label>
                                            <p class="nooscope-reference-desc small">Parametry modelu wyuczone z danych nazywa się <em>parametrami</em>, natomiast te parametry, które nie są wyuczone z danych, lecz ustawione ręcznie, nazywa się <em>hiperparametrami</em> (określają one ilość i właściwości parametrów).</p>
                                        </div>
                                    </li>

                                    <li class="nooscope-reference-list-item">
                                        <div class="nooscope-reference d-flex flex-row">
                                            <label id="nooscope-ref-29-bottom" class="nooscope-reference-num small mr-3 mr-sm-3 mr-md-3 mr-lg-3 mr-xl-3">
                                                <a href="#nooscope-ref-29-top" class="ai-scroll-to">29</a>
                                            </label>
                                            <p class="nooscope-reference-desc small">Rozwiązanie to może być także wyrażone procentowo i przyjmować wartość pomiędzy 0 a 1.</p>
                                        </div>
                                    </li>

                                    <li class="nooscope-reference-list-item">
                                        <div class="nooscope-reference d-flex flex-row">
                                            <label id="nooscope-ref-30-bottom" class="nooscope-reference-num small mr-3 mr-sm-3 mr-md-3 mr-lg-3 mr-xl-3">
                                                <a href="#nooscope-ref-30-top" class="ai-scroll-to">30</a>
                                            </label>
                                            <p class="nooscope-reference-desc small">https://keras.io/applications (dokumentacja poszczególnych modeli).</p>
                                        </div>
                                    </li>

                                    <li class="nooscope-reference-list-item">
                                        <div class="nooscope-reference d-flex flex-row">
                                            <label id="nooscope-ref-31-bottom" class="nooscope-reference-num small mr-3 mr-sm-3 mr-md-3 mr-lg-3 mr-xl-3">
                                                <a href="#nooscope-ref-31-top" class="ai-scroll-to">31</a>
                                            </label>
                                            <p class="nooscope-reference-desc small">Paul Edwards, <cite>A Vast Machine: Computer Models, Climate Data, and The Politics of Global Warming</cite>. Cambridge, MA:</p>
                                        </div>
                                    </li>

                                    <li class="nooscope-reference-list-item">
                                        <div class="nooscope-reference d-flex flex-row">
                                            <label id="nooscope-ref-32-bottom" class="nooscope-reference-num small mr-3 mr-sm-3 mr-md-3 mr-lg-3 mr-xl-3">
                                                <a href="#nooscope-ref-32-top" class="ai-scroll-to">32</a>
                                            </label>
                                            <p class="nooscope-reference-desc small">Zob. także <cite>Wspólny Model Ziemskiego Systemu Klimatycznego</cite> (ang. <cite>Community Earth System Model</cite> <abbr>(CESM)</abbr>) tworzony od 1996 roku przez Narodowe Centrum Badań Atmosferycznych (<abbr>NCAR</abbr>) w Bolder, Kolorado. Community Earth System Model to w pełni sprzężona symulacja numeryczna systemu Ziemi składająca się z atmosfery, oceanu, lodu, powierzchni lądu, obiegu węgla i innych elementów. <abbr>CESM</abbr> zawiera model klimatyczny zapewniający najnowocześniejsze symulacje przeszłości, teraźniejszości i przyszłości Ziemi. http://www.cesm.ucar.edu</p>
                                        </div>
                                    </li>

                                    <li class="nooscope-reference-list-item">
                                        <div class="nooscope-reference d-flex flex-row">
                                            <label id="nooscope-ref-33-bottom" class="nooscope-reference-num small mr-3 mr-sm-3 mr-md-3 mr-lg-3 mr-xl-3">
                                                <a href="#nooscope-ref-33-top" class="ai-scroll-to">33</a>
                                            </label>
                                            <p class="nooscope-reference-desc small">George Box, „Robustness in the Strategy of Scientific Model Building.” Technical Report #1954, Mathematics Research Center, University of Wisconsin-Madison, 1979.</p>
                                        </div>
                                    </li>

                                    <li class="nooscope-reference-list-item">
                                        <div class="nooscope-reference d-flex flex-row">
                                            <label id="nooscope-ref-34-bottom" class="nooscope-reference-num small mr-3 mr-sm-3 mr-md-3 mr-lg-3 mr-xl-3">
                                                <a href="#nooscope-ref-34-top" class="ai-scroll-to">34</a>
                                            </label>
                                            <p class="nooscope-reference-desc small">Postkolonialne oraz poststrukturalistyczne szkoły antropologiczne i etnologiczne podkreślały, że nigdy nie istnieje terytorium <i>per se</i>, ale zawsze występuje także akt terytorializacji.</p>
                                        </div>
                                    </li>

                                    <li class="nooscope-reference-list-item">
                                        <div class="nooscope-reference d-flex flex-row">
                                            <label id="nooscope-ref-35-bottom" class="nooscope-reference-num small mr-3 mr-sm-3 mr-md-3 mr-lg-3 mr-xl-3">
                                                <a href="#nooscope-ref-35-top" class="ai-scroll-to">35</a>
                                            </label>
                                            <p class="nooscope-reference-desc small">Rozpoznawanie wzorców jest jednym z aspektów ekonomii uwagi. <q>Patrzeć znaczy pracować</q>, jak przypomina nam Jonathan Beller. Jonathan Beller, <cite>The Cinematic Mode of Production: Attention Economy and the Society of the Spectacle</cite>. Lebanon, NH: University Press of New England, 2006, 2.</p>
                                        </div>
                                    </li>

                                    <li class="nooscope-reference-list-item">
                                        <div class="nooscope-reference d-flex flex-row">
                                            <label id="nooscope-ref-36-bottom" class="nooscope-reference-num small mr-3 mr-sm-3 mr-md-3 mr-lg-3 mr-xl-3">
                                                <a href="#nooscope-ref-36-top" class="ai-scroll-to">36</a>
                                            </label>
                                            <p class="nooscope-reference-desc small">Dan McQuillan, „Manifesto on Algorithmic Humanitarianism.” Zaprezentowane na sympozjum Reimagining Digital Humanitarianism, Goldsmiths, University of London, 16 lutego 2018.</p>
                                        </div>
                                    </li>

                                    <li class="nooscope-reference-list-item">
                                        <div class="nooscope-reference d-flex flex-row">
                                            <label id="nooscope-ref-37-bottom" class="nooscope-reference-num small mr-3 mr-sm-3 mr-md-3 mr-lg-3 mr-xl-3">
                                                <a href="#nooscope-ref-37-top" class="ai-scroll-to">37</a>
                                            </label>
                                            <p class="nooscope-reference-desc small">Co zostało udowodnione przez twierdzenie o uniwersalnej aproksymacji.</p>
                                        </div>
                                    </li>

                                    <li class="nooscope-reference-list-item">
                                        <div class="nooscope-reference d-flex flex-row">
                                            <label id="nooscope-ref-38-bottom" class="nooscope-reference-num small mr-3 mr-sm-3 mr-md-3 mr-lg-3 mr-xl-3">
                                                <a href="#nooscope-ref-38-top" class="ai-scroll-to">38</a>
                                            </label>
                                            <p class="nooscope-reference-desc small">Ananya Ganesh, Andrew McCallum i Emma Strubell, „Energy and Policy Considerations for Deep Learning in NLP.” ArXiv preprint, 2019. https://arxiv.org/abs/1906.02243</p>
                                        </div>
                                    </li>

                                    <li class="nooscope-reference-list-item">
                                        <div class="nooscope-reference d-flex flex-row">
                                            <label id="nooscope-ref-39-bottom" class="nooscope-reference-num small mr-3 mr-sm-3 mr-md-3 mr-lg-3 mr-xl-3">
                                                <a href="#nooscope-ref-39-top" class="ai-scroll-to">39</a>
                                            </label>
                                            <p class="nooscope-reference-desc small">Cardon i in., „Neurons Spike Back.”</p>
                                        </div>
                                    </li>

                                    <li class="nooscope-reference-list-item">
                                        <div class="nooscope-reference d-flex flex-row">
                                            <label id="nooscope-ref-40-bottom" class="nooscope-reference-num small mr-3 mr-sm-3 mr-md-3 mr-lg-3 mr-xl-3">
                                                <a href="#nooscope-ref-40-top" class="ai-scroll-to">40</a>
                                            </label>
                                            <p class="nooscope-reference-desc small">William Gibson <cite>Neuromancer</cite> w: <cite>Trylogia Ciągu</cite>, przeł. Piotr W. Cholewa, Wydawnictwo MAG, Warszawa 2015, s. 58.</p>
                                        </div>
                                    </li>

                                    <li class="nooscope-reference-list-item">
                                        <div class="nooscope-reference d-flex flex-row">
                                            <label id="nooscope-ref-41-bottom" class="nooscope-reference-num small mr-3 mr-sm-3 mr-md-3 mr-lg-3 mr-xl-3">
                                                <a href="#nooscope-ref-41-top" class="ai-scroll-to">41</a>
                                            </label>
                                            <p class="nooscope-reference-desc small">Źródło: corpling.hypotheses.org/495</p>
                                        </div>
                                    </li>

                                    <li class="nooscope-reference-list-item">
                                        <div class="nooscope-reference d-flex flex-row">
                                            <label id="nooscope-ref-42-bottom" class="nooscope-reference-num small mr-3 mr-sm-3 mr-md-3 mr-lg-3 mr-xl-3">
                                                <a href="#nooscope-ref-42-top" class="ai-scroll-to">42</a>
                                            </label>
                                            <p class="nooscope-reference-desc small">Jamie Morgenstern, Samira Samadi, Mohit Singh, Uthaipon Tantipongpipat i Santosh Vempala, „The Price of Fair PCA: One Extra Dimension.” <cite>Advances in Neural Information Processing Systems </cite>31, 2018.</p>
                                        </div>
                                    </li>

                                    <li class="nooscope-reference-list-item">
                                        <div class="nooscope-reference d-flex flex-row">
                                            <label id="nooscope-ref-43-bottom" class="nooscope-reference-num small mr-3 mr-sm-3 mr-md-3 mr-lg-3 mr-xl-3">
                                                <a href="#nooscope-ref-43-top" class="ai-scroll-to">43</a>
                                            </label>
                                            <p class="nooscope-reference-desc small">O idei wspomaganego i generatywnego tworzenia zob. Roelof Pieters i Samim Winiger, „Creative AI: On the Democratisation and Escalation of Creativity”, 2016. http://www. medium.com/@creativeai/creativeai-9d4b2346faf3</p>
                                        </div>
                                    </li>

                                    <li class="nooscope-reference-list-item">
                                        <div class="nooscope-reference d-flex flex-row">
                                            <label id="nooscope-ref-44-bottom" class="nooscope-reference-num small mr-3 mr-sm-3 mr-md-3 mr-lg-3 mr-xl-3">
                                                <a href="#nooscope-ref-44-top" class="ai-scroll-to">44</a>
                                            </label>
                                            <p class="nooscope-reference-desc small">Os Keyes, „The Misgendering Machines: Trans/HCI Implications of Automatic Gender Recognition.” <cite>Proceedings of the ACM on Human-Computer Interaction</cite> 2(88), listopad 2018. https://doi.org/10.1145/3274357</p>
                                        </div>
                                    </li>

                                    <li class="nooscope-reference-list-item">
                                        <div class="nooscope-reference d-flex flex-row">
                                            <label id="nooscope-ref-45-bottom" class="nooscope-reference-num small mr-3 mr-sm-3 mr-md-3 mr-lg-3 mr-xl-3">
                                                <a href="#nooscope-ref-45-top" class="ai-scroll-to">45</a>
                                            </label>
                                            <p class="nooscope-reference-desc small">Alexander Mordvintsev, Christophe Olah i Mike Tyka, „Inceptionism: Going Deeper into Neural Networks.” Google Research blog, 17 czerwca 2015. https://ai.googleblog.com/2015/06/ inceptionism-going-deeper-into-neural.html</p>
                                        </div>
                                    </li>

                                    <li class="nooscope-reference-list-item">
                                        <div class="nooscope-reference d-flex flex-row">
                                            <label id="nooscope-ref-46-bottom" class="nooscope-reference-num small mr-3 mr-sm-3 mr-md-3 mr-lg-3 mr-xl-3">
                                                <a href="#nooscope-ref-46-top" class="ai-scroll-to">46</a>
                                            </label>
                                            <p class="nooscope-reference-desc small">Deep fake’i są to spreparowane dzieła, takie jak na przykład filmy, w których twarz danej osoby jest podmieniona na twarz kogoś innego, często w celu wytworzenia fake newsów.</p>
                                        </div>
                                    </li>

                                    <li class="nooscope-reference-list-item">
                                        <div class="nooscope-reference d-flex flex-row">
                                            <label id="nooscope-ref-47-bottom" class="nooscope-reference-num small mr-3 mr-sm-3 mr-md-3 mr-lg-3 mr-xl-3">
                                                <a href="#nooscope-ref-47-top" class="ai-scroll-to">47</a>
                                            </label>
                                            <p class="nooscope-reference-desc small">Joseph Paul Cohen, Sina Honari i Margaux Luck, „Distribution Matching Losses Can Hallucinate Features in Medical Image Translation.” International Conference on Medical Image Computing and Computer-Assisted Intervention. Cham: Springer, 2018. arXiv:1805.08841</p>
                                        </div>
                                    </li>

                                    <li class="nooscope-reference-list-item">
                                        <div class="nooscope-reference d-flex flex-row">
                                            <label id="nooscope-ref-48-bottom" class="nooscope-reference-num small mr-3 mr-sm-3 mr-md-3 mr-lg-3 mr-xl-3">
                                                <a href="#nooscope-ref-48-top" class="ai-scroll-to">48</a>
                                            </label>
                                            <p class="nooscope-reference-desc small">Fabian Offert, Neural Network Cultures panel, Transmediale festival and KIM HfG Karlsruhe. Berlin, 1 lutego 2020. http://kim.hfg-karlsruhe.de/events/neural-network-cultures</p>
                                        </div>
                                    </li>

                                    <li class="nooscope-reference-list-item">
                                        <div class="nooscope-reference d-flex flex-row">
                                            <label id="nooscope-ref-49-bottom" class="nooscope-reference-num small mr-3 mr-sm-3 mr-md-3 mr-lg-3 mr-xl-3">
                                                <a href="#nooscope-ref-49-top" class="ai-scroll-to">49</a>
                                            </label>
                                            <p class="nooscope-reference-desc small">Michel Foucault, <cite>Abnormal: Lectures at the Collège de France 1974-1975</cite>. New York: Picador, 2004, 26.</p>
                                        </div>
                                    </li>

                                    <li class="nooscope-reference-list-item">
                                        <div class="nooscope-reference d-flex flex-row">
                                            <label id="nooscope-ref-50-bottom" class="nooscope-reference-num small mr-3 mr-sm-3 mr-md-3 mr-lg-3 mr-xl-3">
                                                <a href="#nooscope-ref-50-top" class="ai-scroll-to">50</a>
                                            </label>
                                            <p class="nooscope-reference-desc small">Na temat norm komputacyjnych zob. Matteo Pasquinelli, „Arcana Mathematica Imperii: The Evolution of Western Computational Norms.’ w: Maria Hlavajova i in. (eds), <cite>Former West</cite>. Cambridge, MA: MIT Press, 2017.</p>
                                        </div>
                                    </li>

                                    <li class="nooscope-reference-list-item">
                                        <div class="nooscope-reference d-flex flex-row">
                                            <label id="nooscope-ref-51-bottom" class="nooscope-reference-num small mr-3 mr-sm-3 mr-md-3 mr-lg-3 mr-xl-3">
                                                <a href="#nooscope-ref-51-top" class="ai-scroll-to">51</a>
                                            </label>
                                            <p class="nooscope-reference-desc small">Paola Ricaurte, „Data Epistemologies, The Coloniality of Power, and Resistance.” <cite>Television &amp; New Media,</cite> 7 marca 2019.</p>
                                        </div>
                                    </li>

                                    <li class="nooscope-reference-list-item">
                                        <div class="nooscope-reference d-flex flex-row">
                                            <label id="nooscope-ref-52-bottom" class="nooscope-reference-num small mr-3 mr-sm-3 mr-md-3 mr-lg-3 mr-xl-3">
                                                <a href="#nooscope-ref-52-top" class="ai-scroll-to">52</a>
                                            </label>
                                            <p class="nooscope-reference-desc small">David Ingold i Spencer Soper, „Amazon Doesn’t Consider the Race of its Customers. Should It?”, Bloomberg, 21 kwietnia 2016. https://www.bloomberg.com/graphics/2016-amazon-same-day</p>
                                        </div>
                                    </li>

                                    <li class="nooscope-reference-list-item">
                                        <div class="nooscope-reference d-flex flex-row">
                                            <label id="nooscope-ref-53-bottom" class="nooscope-reference-num small mr-3 mr-sm-3 mr-md-3 mr-lg-3 mr-xl-3">
                                                <a href="#nooscope-ref-53-top" class="ai-scroll-to">53</a>
                                            </label>
                                            <p class="nooscope-reference-desc small">Cathy O’Neil, <cite>Weapons of Math Destruction</cite>. New York: Broadway Books, 2016, ch 9.</p>
                                        </div>
                                    </li>

                                    <li class="nooscope-reference-list-item">
                                        <div class="nooscope-reference d-flex flex-row">
                                            <label id="nooscope-ref-54-bottom" class="nooscope-reference-num small mr-3 mr-sm-3 mr-md-3 mr-lg-3 mr-xl-3">
                                                <a href="#nooscope-ref-54-top" class="ai-scroll-to">54</a>
                                            </label>
                                            <p class="nooscope-reference-desc small">Chris Anderson, „The End of Theory: The Data Deluge Makes the Scientific Method Obsolete.” <cite>Wired</cite>, 23 czerwca 2008. Dla krytycznych uwag zob.: Fulvio Mazzocchi, „Could Big Data Be the End of Theory in Science? A Few Remarks on the Epistemology of Data-Driven Science.” EMBO Reports 16(10), 2015.
                                            </p>
                                        </div>
                                    </li>

                                    <li class="nooscope-reference-list-item">
                                        <div class="nooscope-reference d-flex flex-row">
                                            <label id="nooscope-ref-55-bottom" class="nooscope-reference-num small mr-3 mr-sm-3 mr-md-3 mr-lg-3 mr-xl-3">
                                                <a href="#nooscope-ref-55-top" class="ai-scroll-to">55</a>
                                            </label>
                                            <p class="nooscope-reference-desc small">Judea Pearl i Dana Mackenzie, <cite>The Book of Why: The New Science of Cause and Effect</cite>. New York: Basic Books, 2018.</p>
                                        </div>
                                    </li>

                                    <li class="nooscope-reference-list-item">
                                        <div class="nooscope-reference d-flex flex-row">
                                            <label id="nooscope-ref-56-bottom" class="nooscope-reference-num small mr-3 mr-sm-3 mr-md-3 mr-lg-3 mr-xl-3">
                                                <a href="#nooscope-ref-56-top" class="ai-scroll-to">56</a>
                                            </label>
                                            <p class="nooscope-reference-desc small">Eksperymenty nowojorskiej policji (NYPD) mają miejsce już od późnych lat osiemdziesiątych. Zob. Pasquinelli, „Arcana Mathematica Imperii.”</p>
                                        </div>
                                    </li>

                                    <li class="nooscope-reference-list-item">
                                        <div class="nooscope-reference d-flex flex-row">
                                            <label id="nooscope-ref-57-bottom" class="nooscope-reference-num small mr-3 mr-sm-3 mr-md-3 mr-lg-3 mr-xl-3">
                                                <a href="#nooscope-ref-57-top" class="ai-scroll-to">57</a>
                                            </label>
                                            <p class="nooscope-reference-desc small">Dan McQuillan, „People’s Councils for Ethical Machine Learning.” <cite>Social Media and Society</cite> 4(2), 2018.</p>
                                        </div>
                                    </li>

                                    <li class="nooscope-reference-list-item">
                                        <div class="nooscope-reference d-flex flex-row">
                                            <label id="nooscope-ref-58-bottom" class="nooscope-reference-num small mr-3 mr-sm-3 mr-md-3 mr-lg-3 mr-xl-3">
                                                <a href="#nooscope-ref-58-top" class="ai-scroll-to">58</a>
                                            </label>
                                            <p class="nooscope-reference-desc small">Ricaurte, „Data Epistemologies.”</p>
                                        </div>
                                    </li>

                                    <li class="nooscope-reference-list-item">
                                        <div class="nooscope-reference d-flex flex-row">
                                            <label id="nooscope-ref-59-bottom" class="nooscope-reference-num small mr-3 mr-sm-3 mr-md-3 mr-lg-3 mr-xl-3">
                                                <a href="#nooscope-ref-59-top" class="ai-scroll-to">59</a>
                                            </label>
                                            <p class="nooscope-reference-desc small">Felix Guattari, <cite>Schizoanalytic Cartographies</cite>. London: Continuum, 2013, 2.</p>
                                        </div>
                                    </li>

                                    <li class="nooscope-reference-list-item">
                                        <div class="nooscope-reference d-flex flex-row">
                                            <label id="nooscope-ref-60-bottom" class="nooscope-reference-num small mr-3 mr-sm-3 mr-md-3 mr-lg-3 mr-xl-3">
                                                <a href="#nooscope-ref-60-top" class="ai-scroll-to">60</a>
                                            </label>
                                            <p class="nooscope-reference-desc small">Związek między SI a hakowaniem nie jest tak odległy jak mogłoby się wydawać: często sprowadza się on do pętli wzajemnego uczenia się, oceny i wzmocnienia.</p>
                                        </div>
                                    </li>

                                    <li class="nooscope-reference-list-item">
                                        <div class="nooscope-reference d-flex flex-row">
                                            <label id="nooscope-ref-61-bottom" class="nooscope-reference-num small mr-3 mr-sm-3 mr-md-3 mr-lg-3 mr-xl-3">
                                                <a href="#nooscope-ref-61-top" class="ai-scroll-to">61</a>
                                            </label>
                                            <p class="nooscope-reference-desc small">Adam Harvey, HyperFace project, 2016. https://ahprojects.com/hyperface</p>
                                        </div>
                                    </li>

                                    <li class="nooscope-reference-list-item">
                                        <div class="nooscope-reference d-flex flex-row">
                                            <label id="nooscope-ref-62-bottom" class="nooscope-reference-num small mr-3 mr-sm-3 mr-md-3 mr-lg-3 mr-xl-3">
                                                <a href="#nooscope-ref-62-top" class="ai-scroll-to">62</a>
                                            </label>
                                            <p class="nooscope-reference-desc small">Anish Athalye i in., „Synthesizing Robust Adversarial Examples.” ArXiv preprint, 2017. https://arxiv.org/abs/1707.07397</p>
                                        </div>
                                    </li>

                                    <li class="nooscope-reference-list-item">
                                        <div class="nooscope-reference d-flex flex-row">
                                            <label id="nooscope-ref-63-bottom" class="nooscope-reference-num small mr-3 mr-sm-3 mr-md-3 mr-lg-3 mr-xl-3">
                                                <a href="#nooscope-ref-63-top" class="ai-scroll-to">63</a>
                                            </label>
                                            <p class="nooscope-reference-desc small">Nir Morgulis i in., „Fooling a Real Car with Adversarial Traffic Signs.” ArXiv preprint, 2019. https://arxiv.org/abs/1907.00374</p>
                                        </div>
                                    </li>

                                    <li class="nooscope-reference-list-item">
                                        <div class="nooscope-reference d-flex flex-row">
                                            <label id="nooscope-ref-64-bottom" class="nooscope-reference-num small mr-3 mr-sm-3 mr-md-3 mr-lg-3 mr-xl-3">
                                                <a href="#nooscope-ref-64-top" class="ai-scroll-to">64</a>
                                            </label>
                                            <p class="nooscope-reference-desc small">Zatruwanie danych może być także wykorzystanie w celu ochrony prywatności poprzez wprowadzanie anonimowych lub losowych informacji do zbioru danych.</p>
                                        </div>
                                    </li>

                                    <li class="nooscope-reference-list-item">
                                        <div class="nooscope-reference d-flex flex-row">
                                            <label id="nooscope-ref-65-bottom" class="nooscope-reference-num small mr-3 mr-sm-3 mr-md-3 mr-lg-3 mr-xl-3">
                                                <a href="#nooscope-ref-65-top" class="ai-scroll-to">65</a>
                                            </label>
                                            <p class="nooscope-reference-desc small">Ian Goodfellow i in., „Explaining and Harnessing Adversarial Examples.” ArXiv preprint, 2014. https://arxiv.org/abs/1412.6572</p>
                                        </div>
                                    </li>

                                    <li class="nooscope-reference-list-item">
                                        <div class="nooscope-reference d-flex flex-row">
                                            <label id="nooscope-ref-66-bottom" class="nooscope-reference-num small mr-3 mr-sm-3 mr-md-3 mr-lg-3 mr-xl-3">
                                                <a href="#nooscope-ref-66-top" class="ai-scroll-to">66</a>
                                            </label>
                                            <p class="nooscope-reference-desc small">Florian Schmidt, „Crowdsourced Production of AI Training Data: How Human Workers Teach Self-Driving Cars to See.” Düsseldorf: Hans-Böckler-Stiftung, 2019.</p>
                                        </div>
                                    </li>

                                    <li class="nooscope-reference-list-item">
                                        <div class="nooscope-reference d-flex flex-row">
                                            <label id="nooscope-ref-67-bottom" class="nooscope-reference-num small mr-3 mr-sm-3 mr-md-3 mr-lg-3 mr-xl-3">
                                                <a href="#nooscope-ref-67-top" class="ai-scroll-to">67</a>
                                            </label>
                                            <p class="nooscope-reference-desc small">Hamid Ekbia i Bonnie Nardi, <cite>Heteromation, and Other Stories of Computing and Capitalism</cite>. Cambridge, MA: MIT Press, 2017.</p>
                                        </div>
                                    </li>

                                    <li class="nooscope-reference-list-item">
                                        <div class="nooscope-reference d-flex flex-row">
                                            <label id="nooscope-ref-68-bottom" class="nooscope-reference-num small mr-3 mr-sm-3 mr-md-3 mr-lg-3 mr-xl-3">
                                                <a href="#nooscope-ref-68-top" class="ai-scroll-to">68</a>
                                            </label>
                                            <p class="nooscope-reference-desc small">O idei inteligencji analitycznej zob. Lorraine Daston, „Calculation and the Division of Labour 1750–1950.” <cite>Bulletin of the German Historical Institute</cite> 62, 2018.</p>
                                        </div>
                                    </li>

                                    <li class="nooscope-reference-list-item">
                                        <div class="nooscope-reference d-flex flex-row">
                                            <label id="nooscope-ref-69-bottom" class="nooscope-reference-num small mr-3 mr-sm-3 mr-md-3 mr-lg-3 mr-xl-3">
                                                <a href="#nooscope-ref-69-top" class="ai-scroll-to">69</a>
                                            </label>
                                            <p class="nooscope-reference-desc small">Simon Schaffer, „Babbage’s Intelligence: Calculating Engines and the Factory System”, Critical Inquiry 21, 1994. Lorraine Daston, „Enlightenment calculations”. Critical Inquiry 21, 1994. Matthew L. Jones, <cite>Reckoning with Matter: Calculating Machines, Innovation, and Thinking about Thinking from Pascal to Babbage.</cite> Chicago: University of Chicago Press, 2016. 62, 2018.</p>
                                        </div>
                                    </li>

                                    <li class="nooscope-reference-list-item">
                                        <div class="nooscope-reference d-flex flex-row">
                                            <label id="nooscope-ref-70-bottom" class="nooscope-reference-num small mr-3 mr-sm-3 mr-md-3 mr-lg-3 mr-xl-3">
                                                <a href="#nooscope-ref-70-top" class="ai-scroll-to">70</a>
                                            </label>
                                            <p class="nooscope-reference-desc small">Matteo Pasquinelli, „On the Origins of Marx’s General Intellect.”<cite> Radical Philosophy</cite> 2.06, 2019.</p>
                                        </div>
                                    </li>

                                    <li class="nooscope-reference-list-item">
                                        <div class="nooscope-reference d-flex flex-row">
                                            <label id="nooscope-ref-71-bottom" class="nooscope-reference-num small mr-3 mr-sm-3 mr-md-3 mr-lg-3 mr-xl-3">
                                                <a href="#nooscope-ref-71-top" class="ai-scroll-to">71</a>
                                            </label>
                                            <p class="nooscope-reference-desc small">Aida Ponce, „Labour in the Age of AI: Why Regulation is Needed to Protect Workers.” ETUI Research Paper - Foresight Brief 8, 2020. http://dx.doi.org/10.2139/ssrn.3541002</p>
                                        </div>
                                    </li>

                                    <li class="nooscope-reference-list-item">
                                        <div class="nooscope-reference d-flex flex-row">
                                            <label id="nooscope-ref-72-bottom" class="nooscope-reference-num small mr-3 mr-sm-3 mr-md-3 mr-lg-3 mr-xl-3">
                                                <a href="#nooscope-ref-72-top" class="ai-scroll-to">72</a>
                                            </label>
                                            <p class="nooscope-reference-desc small">Maxine Berg, <cite>The Machinery Question and the Making of Political Economy</cite>. Cambridge, UK: Cambridge University Press, 1980. W rzeczywistości The Economist przestrzegał niedawno przed "powrotem pytania o maszynę" w erze sztucznej inteligencji. Zob. Tom Standage, „The Return of the Machinery Question.” <cite>The Economist</cite>, 23 czerwca 2016.</p>
                                        </div>
                                    </li>
                                </ul>
                            </section>
                        </article>

                        <section>
                            <h2 class="credits">Pliki</h2>
                            <ul class="ai-download-list list-unstyled bottom_padding">
                                <li class="ai-download-list-item">
                                    <p class="ai-download-link small">
                                        <!-- @todo link -->
                                        Diagram PDF (wkrótce dostępny)
<!--                                        <a href="" target="_blank">Diagram PDF</a>-->
                                    </p>
                                </li>
                                <li class="ai-download-list-item  ">
                                    <p class="ai-download-link small">
                                        <!-- @todo link -->
                                        Esej PDF (wkrótce dostępny)
<!--                                        <a href="" target="_blank">Esej PDF</a>-->
                                    </p>
                                </li>
                            </ul>
                            <br>
                            <br>
                        </section>

                        <section>
                            <h2 class="credits">Podziękowania i dodatkowe informacje</h2>
                            <ul class="ai-credits-list list-unstyled">
                                <li class="ai-credits-list-item">
                                    <p class="small"><strong>Autorzy:</strong> Vladan Joler i Matteo Pasquinelli</p>
                                    <p class="small"><strong>Vladan Joler</strong> jest profesorem Akademii Sztuk Pięknych przy Uniwersytecie w Nowym Sadzie oraz założycielem fundacji SHARE. Prowadzi SHARE Lab, laboratorium badawcze, które eksploruje techniczne i społeczne aspekty transparentności algorytmów, wyzysk pracowników cyfrowych, niewidoczne struktury i technologiczne czarne skrzynki.</p>
                                    <p class="small"><strong>Matteo Pasquinelli</strong> jest profesorem Filozofii Mediów Uniwersytetu Sztuki i Designu w Karlsruhe i koordynatorem grupy badawczej KIM zajmującej się sztuczną inteligencją i filozofią mediów. Dla Verso Books przygotowuje monografię o historii SI, roboczo zatytułowaną <em>The Eye of the Master</em>.</p>
                                </li>
                                <li class="ai-credits-list-item">
                                    <p class="small"><strong>Cytowanie:</strong>
                                        Matteo Pasquinelli, Vladan Joler, <cite>Nooskop ujawniony - manifest: Sztuczna inteligencja jako narzędzie ekstraktywizmu wiedzy</cite>, esej wizualny, tłum. Agnieszka Zgud, Cezary Stępkowski, Kuba Kulesza, MVU, 21 stycznia 2021. <a href="https://nooskop.mvu.pl/" target="_blank">https://nooskop.mvu.pl</a>
                                    </p>
                                </li>
                                <li class="ai-credits-list-item">
                                    <p class="small"><strong>Email:</strong>
                                        <a href="mailto:txt@mvu.pl">txt@mvu.pl</a>
                                    </p>
                                </li>
                                <li class="ai-credits-list-item last-of-type">
                                    <p class="small bottom_padding"><strong>Podziękowania autorów: </strong>Jon Beller, Kate Crawford, Dubravko Ćulibrk, Ariana Dongus, Claire Glanois, Adam Harvey, Leonardo Impett, Arif Kornweitz, Wietske Maas, Dan McQuillan, Fabian Offert, Godofredo Pereira, Johannes Paul Raether, Natascha Sadr Haghighian, Olivia Solis, Mitch Speed i całej społeczności wokół KIM HfG Karlsruhe za wkład i komentarze.</p>
                                </li>
                                <li class="ai-credits-list-item last-of-type">
                                    <p class="small bottom_padding"><strong>Podziękowania tłumaczy: </strong>Alexander Juda, Aleksandra Kleczka, Dawid Prząda.</p>
                                </li>
                            </ul>
                            <br>
                            <br>
                        </section>
                        <section>
                            <h2 class="credits"></h2>
                            <div class="text-center bottom_padding">
                                <a href="http://kim.hfg-karlsruhe.de/" target="_blank"><img class="img-fluid logo" src="img/Logos_KIM.svg" alt="KIM"></a>
                                <a href="https://labs.rs/" target="_blank"> <img class="img-fluid logo" src="img/LOGO_SHARE_SHARE.jpg" alt="Share Lab"></a>
                                <a href="https://mvu.pl/" target="_blank"><img class="img-fluid logo" src="img/mvulogo.svg" alt="Minimum Viable Utopia"></a>
                            </div>
                        </section>
                    </div>
                </div>
            </div>
        </main>

        <!-- Scroll to Top Button-->
        <a class="ai-scroll-to-top rounded" href="#ai-page-top">
            <i class="fa fa-angle-up"></i>
        </a>

        <script src="vendor/jquery/jquery.min.js"></script>
        <script src="vendor/popper/popper.min.js"></script>
        <script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
        <script src="vendor/modernizr/modernizr.min.js"></script>
        <script src="vendor/jquery-easing/jquery.easing.min.js"></script>
        <script src="js/main.js"></script>
    </body>
</html>
